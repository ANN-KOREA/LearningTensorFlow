{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chap07.4 - 텐서플로 추상화와 간소화, TF-Slim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.5 TF-Slim\n",
    "\n",
    "[**TF-Slim**](https://github.com/tensorflow/tensorflow/tree/r1.8/tensorflow/contrib/slim)은 텐서플로를 가볍게(?) 사용할 수 있는 텐서플로의 확장된 추상화 라이브러리이며, 복잡한 모델을 빠르고 직관적으로 정의하고 학습할 수 있다. TF-Slim은 텐서플로 내에 포함되어 있으므로 별도의 설치를 하지 않아도 된다. \n",
    "\n",
    "TF-Slim의 추상화는 모두 [**CNN**](http://excelsior-cjh.tistory.com/152?category=940399)(Convolutional Neural Network)에 관한 것이다. CNN의 경우 동일한 합성곱 계층(Convolution Layer)을 여러번 재사용하는 [보일러플레이트](https://en.wikipedia.org/wiki/Boilerplate_code)(boilerplate code)코드가 많다. 이러한 코드가 많을 경우 모델이 복잡해질 뿐만아니라 가독성 또한 떨어지게 된다. TF-Slim은 이러한 복잡한 CNN 모델을 High-Level, 추상화, arument scoping 등을 이용해 깔끔하게 작성할 수 있게 해준다. \n",
    "\n",
    "또한, TF-Slim은 자체적인 모델을 생성하고 학습할 수 있을 뿐만아니라, 사전에 학습된 모델인 [VGG](https://github.com/tensorflow/tensorflow/blob/r1.8/tensorflow/contrib/slim/python/slim/nets/vgg.py), [AlexNet](https://github.com/tensorflow/tensorflow/blob/r1.8/tensorflow/contrib/slim/python/slim/nets/alexnet.py), [Inception](https://github.com/tensorflow/tensorflow/blob/r1.8/tensorflow/contrib/slim/python/slim/nets/inception.py) 등을 제공한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.5.1 TF-Slim 기능 및 사용방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Usage\n",
    "\n",
    "TF-Slim을 사용하기 위해서는 다음의 코드로 TF-Slim을 임포트한다.\n",
    "\n",
    "```python\n",
    "import tensorflow.contrib.slim as slim\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variables\n",
    "\n",
    "TF-Slim은 초기화(`initializer`), 정규화(`regularizer`), 디바이스(`device`)를 하나의 래퍼(Wrapper)로 정의하여 변수를 쉽게 만들 수 있다. 아래의 예제 코드는 L2 정규화와 CPU를 사용하는 절단정규분포(`truncated_normal_initializer()`)로 초기화한 가중치(변수) `weights`를 정의하는 코드이다.\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "\n",
    "weights = slim.variable('weights', \n",
    "                        shape=[10, 10, 3, 3],\n",
    "                        initializer=tf.truncated_normal_initializer(stddev=0.1),\n",
    "                        regularizer=slim.l2_regularizer(0.05),\n",
    "                        device='/CPU:0')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Layers\n",
    "\n",
    "TF-Slim을 이용하면 순수 텐서플로를 이용해서 CNN 모델을 구현하는 것보다 훨씬 짧은 코드로 구현할 수 있다. 특히 보일러플레이트 코드와 불필요한 중복을 제거할 수 있다. 먼저, 합성곱 계층을 TF-Slim을 이용해서 정의 해보자.\n",
    "\n",
    "```python\n",
    "# 샘플 코드\n",
    "net = slim.conv2d(inputs, 64, [5, 5], padding='SAME',\n",
    "                  weights_initalizer=tf.truncated_normal_initializer(stddev=0.01),\n",
    "                  weights_regularizer=slim.l2_regularizer(0.0005), scop='conv1')\n",
    "```\n",
    "\n",
    "위의 샘플 코드에서 처럼 합성곱 연산, 가중치 초기화, 정규화, 활성화 함수 등을 한번에 설정해줄 수 있다.\n",
    "\n",
    "그리고, TF-slim은 `repeat`을 이용해 동일한 합성곱 계층들을 한줄로 표현할 수 있다. 아래의 코드는 5개의 동일한 합성곱 계층을 \n",
    "쌓은 것을 나타낸 코드이다.\n",
    "```python\n",
    "# 샘플코드 - 같은 합성곱 계층을 5번 쌓기\n",
    "net = slim.conv2d(net, 128, [3, 3], scope='con1_1')\n",
    "net = slim.conv2d(net, 128, [3, 3], scope='con1_2')\n",
    "net = slim.conv2d(net, 128, [3, 3], scope='con1_3')\n",
    "net = slim.conv2d(net, 128, [3, 3], scope='con1_4')\n",
    "net = slim.conv2d(net, 128, [3, 3], scope='con1_5')\n",
    "```\n",
    "\n",
    "위의 코드를 `repeat()`을 이용해 한줄로 나타낼 수 있다. 단, `repeat`은 계층의 크기가 동일한 경우에만 사용 가능하다.\n",
    "\n",
    "```python\n",
    "# 샘플코드 - slim.repeat()을 이용해 한줄로 나타내기\n",
    "net = slim.repeat(net, 5, slim.conv2d, 128, [3, 3], scope='con1')\n",
    "```\n",
    "\n",
    "만약, 형태가 다른 경우에는 `stack`을 이용해 나타낼 수 있다.\n",
    "\n",
    "```python\n",
    "# 샘플코드 - 형태가 다른 합성곱 계층을 5개 쌓기\n",
    "net = slim.conv2d(net, 64, [3, 3], scope='con1_1')\n",
    "net = slim.conv2d(net, 64, [1, 1], scope='con1_2')\n",
    "net = slim.conv2d(net, 128, [3, 3], scope='con1_3')\n",
    "net = slim.conv2d(net, 128, [1, 1], scope='con1_4')\n",
    "net = slim.conv2d(net, 256, [3, 3], scope='con1_5')\n",
    "\n",
    "# 샘플코드 - slim.stack()을 이용해 한줄로 나타내기\n",
    "net = slim.stack(net, slim.conv2d, [(64, [3, 3]), (64, [1, 1]),\n",
    "                                    (128, [3, 3]), (128, [1, 1]),\n",
    "                                    (256, [3, 3])], scope='con')\n",
    "```\n",
    "\n",
    "TF-Slim에는 `slim.conv2d` 계층 뿐만아니라 아래의 표와 같이 다양한 계층을 사용할 수 있다.\n",
    "\n",
    "| Layer                    | TF-Slim                                                      |\n",
    "| ------------------------ | ------------------------------------------------------------ |\n",
    "| BiasAdd                  | [slim.bias_add](https://www.tensorflow.org/code/tensorflow/contrib/layers/python/layers/layers.py) |\n",
    "| BatchNorm                | [slim.batch_norm](https://www.tensorflow.org/code/tensorflow/contrib/layers/python/layers/layers.py) |\n",
    "| Conv2d                   | [slim.conv2d](https://www.tensorflow.org/code/tensorflow/contrib/layers/python/layers/layers.py) |\n",
    "| Conv2dInPlane            | [slim.conv2d_in_plane](https://www.tensorflow.org/code/tensorflow/contrib/layers/python/layers/layers.py) |\n",
    "| Conv2dTranspose (Deconv) | [slim.conv2d_transpose](https://www.tensorflow.org/code/tensorflow/contrib/layers/python/layers/layers.py) |\n",
    "| FullyConnected           | [slim.fully_connected](https://www.tensorflow.org/code/tensorflow/contrib/layers/python/layers/layers.py) |\n",
    "| AvgPool2D                | [slim.avg_pool2d](https://www.tensorflow.org/code/tensorflow/contrib/layers/python/layers/layers.py) |\n",
    "| Dropout                  | [slim.dropout](https://www.tensorflow.org/code/tensorflow/contrib/layers/python/layers/layers.py) |\n",
    "| Flatten                  | [slim.flatten](https://www.tensorflow.org/code/tensorflow/contrib/layers/python/layers/layers.py) |\n",
    "| MaxPool2D                | [slim.max_pool2d](https://www.tensorflow.org/code/tensorflow/contrib/layers/python/layers/layers.py) |\n",
    "| OneHotEncoding           | [slim.one_hot_encoding](https://www.tensorflow.org/code/tensorflow/contrib/layers/python/layers/layers.py) |\n",
    "| SeparableConv2           | [slim.separable_conv2d](https://www.tensorflow.org/code/tensorflow/contrib/layers/python/layers/layers.py) |\n",
    "| UnitNorm                 | [slim.unit_norm](https://www.tensorflow.org/code/tensorflow/contrib/layers/python/layers/layers.py) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### arg_scope\n",
    "\n",
    "TF-Slim은 `arg_scope`이라는 스코프를 가지고 있는데, 이것을 이용하면 같은 스코프에 정의되어 있는 여러 계층에 같은 인자들을 한번에 전달할 수 있다. 아래의 샘플 코드는 `slim.arg_scope`을 이용해 패딩, 활성화함수, 초기화, 정규화를 `slim.conv2d` 계층에 동일하게 설정하는 코드이다.\n",
    "\n",
    "```python\n",
    "# 샘플코드 - arg_scope을 이용해 slim.conv2d에 같은 인자 설정하기\n",
    "with slim.arg_scope([slim.conv2d],\n",
    "                    padding='SAME',\n",
    "                    activation_fn=tf.nn.elu,\n",
    "                    weights_initializer=tf.truncated_normal_initializer(stddev=0.01)):\n",
    "    inputs = tf.reshape(x, [-1, 28, 28, 1])\n",
    "    \n",
    "    net = slim.conv2d(inputs=inputs, num_outputs=32, kernel_size=[5, 5], scope='conv1')\n",
    "    net = slim.max_pool2d(inputs=net, kernel_size=[2, 2], scope='pool1')\n",
    "    net = slim.conv2d(net, 64, [5, 5], scope='conv2')\n",
    "    net = slim.max_pool2d(net, [2, 2], scope='pool2')\n",
    "    net = slim.flatten(net, scope='flatten3')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.5.2 TF-Slim으로 MNIST 분류 CNN 모델 구현하기\n",
    "\n",
    "TF-Slim의 사용방법을 알아보았으니, 이번에는 [Chap04 - 합성곱 신경망 CNN](http://excelsior-cjh.tistory.com/152?category=940399)에서 구현한 CNN모델을 TF-Slim을 이용해 구현해 보도록하자. 7.5.1에서 TF-Slim에 대한 각 기능을 샘플코드로 살펴보았기 때문에 별도의 코드 설명은 생략한다. \n",
    "\n",
    "TF-Slim을 이용해 구현한 MNIST 분류 CNN 모델의 전체코드는 다음과 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step : 500, cost : 0.18137, training accuracy: 0.98000\n",
      "Step : 1000, cost : 0.16081, training accuracy: 0.96000\n",
      "Step : 1500, cost : 0.25697, training accuracy: 0.92000\n",
      "Step : 2000, cost : 0.11345, training accuracy: 0.96000\n",
      "Step : 2500, cost : 0.03990, training accuracy: 1.00000\n",
      "Step : 3000, cost : 0.07193, training accuracy: 1.00000\n",
      "Step : 3500, cost : 0.08555, training accuracy: 0.94000\n",
      "Step : 4000, cost : 0.06140, training accuracy: 1.00000\n",
      "Step : 4500, cost : 0.09817, training accuracy: 0.98000\n",
      "Step : 5000, cost : 0.00845, training accuracy: 1.00000\n",
      "test accuracy: 0.98220\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "\n",
    "#######################\n",
    "# 0. mnist 불러오기\n",
    "def mnist_load():\n",
    "    (train_x, train_y), (test_x, test_y) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "    # Train - Image\n",
    "    train_x = train_x.astype('float32') / 255\n",
    "    # Train - Label(OneHot)\n",
    "    train_y = tf.keras.utils.to_categorical(train_y, num_classes=10)\n",
    "\n",
    "    # Test - Image\n",
    "    test_x = test_x.astype('float32') / 255\n",
    "    # Test - Label(OneHot)\n",
    "    test_y = tf.keras.utils.to_categorical(test_y, num_classes=10)\n",
    "    \n",
    "    return (train_x, train_y), (test_x, test_y)\n",
    "\n",
    "\n",
    "(train_x, train_y), (test_x, test_y) = mnist_load()\n",
    "\n",
    "\n",
    "#######################\n",
    "# 1. placeholder 정의\n",
    "x = tf.placeholder(tf.float32, shape=[None, 28, 28])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "is_training = tf.placeholder(tf.bool)\n",
    "\n",
    "########################\n",
    "# 2. TF-Slim을 이용한 CNN 모델 구현\n",
    "with slim.arg_scope([slim.conv2d],\n",
    "                    padding='SAME',\n",
    "                    activation_fn=tf.nn.elu,\n",
    "                    weights_initializer=tf.truncated_normal_initializer(stddev=0.01)):\n",
    "    inputs = tf.reshape(x, [-1, 28, 28, 1])\n",
    "    \n",
    "    net = slim.conv2d(inputs=inputs, num_outputs=32, kernel_size=[5, 5], scope='conv1')\n",
    "    net = slim.max_pool2d(inputs=net, kernel_size=[2, 2], scope='pool1')\n",
    "    net = slim.conv2d(net, 64, [5, 5], scope='conv2')\n",
    "    net = slim.max_pool2d(net, [2, 2], scope='pool2')\n",
    "    net = slim.flatten(net, scope='flatten3')\n",
    "    \n",
    "with slim.arg_scope([slim.fully_connected],\n",
    "                    weights_initializer=tf.truncated_normal_initializer(stddev=0.01)):\n",
    "    net = slim.fully_connected(net, 1024, activation_fn=tf.nn.relu, scope='fc3')\n",
    "    net = slim.dropout(net, is_training=is_training, scope='dropout3')\n",
    "    outputs = slim.fully_connected(net, 10, activation_fn=None)\n",
    "    \n",
    "########################\n",
    "# 3. loss, optimizer, accuracy\n",
    "# loss\n",
    "cross_entropy = tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits_v2(logits=outputs, labels=y_))\n",
    "# optimizer\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "# accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(outputs, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "########################\n",
    "# 4. Hyper-Paramter 설정 및 데이터 설정\n",
    "# Hyper Parameters\n",
    "STEPS = 5000\n",
    "MINI_BATCH_SIZE = 50\n",
    "\n",
    "# tf.data.Dataset을 이용한 배치 크기 만큼 데이터 불러오기\n",
    "dataset = tf.data.Dataset.from_tensor_slices(({\"image\": train_x}, train_y))\n",
    "dataset = dataset.shuffle(100000).repeat().batch(MINI_BATCH_SIZE)\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "next_batch = iterator.get_next()\n",
    "\n",
    "########################\n",
    "# Training & Testing\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # 학습\n",
    "    for step in range(STEPS):\n",
    "        batch_xs, batch_ys = sess.run(next_batch)\n",
    "        _, cost_val = sess.run([train_step, cross_entropy], feed_dict={x: batch_xs['image'], \n",
    "                                                                       y_: batch_ys, \n",
    "                                                                       is_training: True})\n",
    "        \n",
    "        if (step+1) % 500 == 0:\n",
    "            train_accuracy = sess.run(accuracy, feed_dict={x: batch_xs['image'],\n",
    "                                                           y_: batch_ys, \n",
    "                                                           is_training: False})\n",
    "            print(\"Step : {}, cost : {:.5f}, training accuracy: {:.5f}\".format(step+1, cost_val, \n",
    "                                                                               train_accuracy))\n",
    "            \n",
    "    X = test_x.reshape([10, 1000, 28, 28])\n",
    "    Y = test_y.reshape([10, 1000, 10])\n",
    "\n",
    "    test_accuracy = np.mean(\n",
    "            [sess.run(accuracy, feed_dict={x: X[i], \n",
    "                                           y_: Y[i], \n",
    "                                           is_training: False}) for i in range(10)])\n",
    "\n",
    "print(\"test accuracy: {:.5f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.5.3 TF-Slim으로 VGG-16 모델 구현하기\n",
    "\n",
    "TF-Slim을 이용해 CNN 모델 중 [VGG](https://arxiv.org/abs/1409.1556)모델을 구현해 보도록 하자. VGG모델은 2014년에 발표된 모델이며, 2014년 [ISLVRC](http://www.image-net.org/challenges/LSVRC/)에서 2위를 차지한 모델이다. VGG는 계층의 수가 16일때와 19사이일 때 결과가 가장 좋으며, 이번 예제에서는 TF-Slim을 이용해 13개의 합성곱 계층(Conv layer)와 3개의 완전연결 계층(FC, Fully-Connected layer), VGG-16 모델을 구현해 본다. 이번 예제 코드는 단순히 모델만 구현하는 것이므로 데이터 입력 및 학습에 대한 코드는 포함하지 않았다.\n",
    "\n",
    "<img src=\"./images/vgg.png\" height=\"90%\" width=\"90%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 그림에서 보듯이 VGG-16은 동일한 계층을 여러번 쓰는것을 확인할 수 있다. 따라서, TF-Slim의 `slim.arg_scope`와 `slim.repeat`을 이용해 VGG-16을 구현할 수 있다.\n",
    "\n",
    "```python\n",
    "# https://github.com/tensorflow/tensorflow/tree/r1.8/tensorflow/contrib/slim\n",
    "def vgg16(inputs):\n",
    "    with slim.arg_scope([slim.conv2d, slim.fully_connected],\n",
    "                          activation_fn=tf.nn.relu,\n",
    "                          weights_initializer=tf.truncated_normal_initializer(0.0, 0.01),\n",
    "                          weights_regularizer=slim.l2_regularizer(0.0005)):\n",
    "        net = slim.repeat(inputs, 2, slim.conv2d, 64, [3, 3], scope='conv1')\n",
    "        net = slim.max_pool2d(net, [2, 2], scope='pool1')\n",
    "        net = slim.repeat(net, 2, slim.conv2d, 128, [3, 3], scope='conv2')\n",
    "        net = slim.max_pool2d(net, [2, 2], scope='pool2')\n",
    "        net = slim.repeat(net, 3, slim.conv2d, 256, [3, 3], scope='conv3')\n",
    "        net = slim.max_pool2d(net, [2, 2], scope='pool3')\n",
    "        net = slim.repeat(net, 3, slim.conv2d, 512, [3, 3], scope='conv4')\n",
    "        net = slim.max_pool2d(net, [2, 2], scope='pool4')\n",
    "        net = slim.repeat(net, 3, slim.conv2d, 512, [3, 3], scope='conv5')\n",
    "        net = slim.max_pool2d(net, [2, 2], scope='pool5')\n",
    "        net = slim.fully_connected(net, 4096, scope='fc6')\n",
    "        net = slim.dropout(net, 0.5, scope='dropout6')\n",
    "        net = slim.fully_connected(net, 4096, scope='fc7')\n",
    "        net = slim.dropout(net, 0.5, scope='dropout7')\n",
    "        net = slim.fully_connected(net, 1000, activation_fn=None, scope='fc8')\n",
    "    return net\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.5.4 사전 학습된 VGG-16모델 사용하기\n",
    "\n",
    "이번에는 사전 학습된 VGG 모델을 다운로드 받아 사용해보자. 아래의 예제코드는 이미지 url 경로(http://54.68.5.226/car.jpg) 를 `urlib`모듈을 이용해 읽은 다음, 이 이미지를 사전 학습된 VGG-16 모델을 가지고 분류하는 작업을 나타낸 코드이다. \n",
    "\n",
    "<img src=\"http://54.68.5.226/car.jpg\" width=\"50%\" height=\"50%\"/>\n",
    "\n",
    "먼저, [TensorFlow](https://github.com/tensorflow/)가 제공하는 모델들이 있는 GitHub 저장소를 클론한다.\n",
    "\n",
    "```bash\n",
    "git clone https://github.com/tensorflow/models\n",
    "```\n",
    "\n",
    "그런 다음 클론한 경로를 파이썬의 `sys` 모듈을 이용해 설정해준다.\n",
    "\n",
    "```python\n",
    "import sys\n",
    "sys.path.append('<클론한 경로>' + '/models/research/slim')\n",
    "```\n",
    "\n",
    "그리고, 사전 학습된 VGG-16 모델을 [download.tensorflow.org](http://download.tensorflow.org/models/vgg_16_2016_08_28.tar.gz)에서 다운로드 받은 후 적당한 위치에 압축을 풀어주고 이것을 `target_dir`로 지정한다.\n",
    "\n",
    "```python\n",
    "target_dir = '<vgg 사전학습된 모델이 있는 경로>'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "# clone한 경로 설정\n",
    "sys.path.append('/home/cjh/D/dev/models/research/slim')\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "from tensorflow.contrib.slim.nets import vgg\n",
    "\n",
    "from urllib.request import urlopen\n",
    "from datasets import dataset_utils, imagenet\n",
    "from preprocessing import vgg_preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../data/vgg16/vgg_16.ckpt\n",
      "Class: sports car, sport car\t|Prob: 0.6969962\n",
      "Class: car wheel\t|Prob: 0.09234831\n",
      "Class: convertible\t|Prob: 0.0891054\n",
      "Class: racer, race car, racing car\t|Prob: 0.08648531\n",
      "Class: beach wagon, station wagon, wagon, estate car, beach waggon, station waggon, waggon\t|Prob: 0.011633869\n"
     ]
    }
   ],
   "source": [
    "########################\n",
    "# 0. 사전학습된 vgg16 경로 설정\n",
    "# Pre-trained vgg16\n",
    "target_dir = '../data/vgg16'\n",
    "\n",
    "########################\n",
    "# 1. 샘플 이미지를 vgg16 입력에 맞게 설정\n",
    "# sample image\n",
    "url = 'http://54.68.5.226/car.jpg'\n",
    "\n",
    "img_as_string = urlopen(url).read()\n",
    "image = tf.image.decode_jpeg(img_as_string, channels=3)\n",
    "\n",
    "image_size = vgg.vgg_16.default_image_size  # image_size = 224\n",
    "\n",
    "# vgg_preprocessing을 이용해 전처리 수행\n",
    "processed_img = vgg_preprocessing.preprocess_image(image,\n",
    "                                                   image_size,\n",
    "                                                   image_size,\n",
    "                                                   is_training=False)\n",
    "\n",
    "processed_images = tf.expand_dims(processed_img, 0)\n",
    "\n",
    "#########################\n",
    "# 2. slim.arg_scope을 이용해 vgg16 예측값 설정\n",
    "def vgg_arg_scope(weight_decay=0.0005):\n",
    "    with slim.arg_scope([slim.conv2d, slim.fully_connected],\n",
    "                        activation_fn=tf.nn.relu,\n",
    "                        weights_regularizer=slim.l2_regularizer(weight_decay), \n",
    "                        biases_initializer=tf.zeros_initializer):\n",
    "        with slim.arg_scope([slim.conv2d], padding='SAME') as arg_sc:\n",
    "            return arg_sc\n",
    "\n",
    "with slim.arg_scope(vgg.vgg_arg_scope()):\n",
    "    logits, _ = vgg.vgg_16(processed_images, \n",
    "                           num_classes=1000, \n",
    "                           is_training=False)\n",
    "probabilities = tf.nn.softmax(logits)\n",
    "\n",
    "##########################\n",
    "# 3. 사전 학습된 vgg16 모델 불러오기\n",
    "load_vars = slim.assign_from_checkpoint_fn(\n",
    "    os.path.join(target_dir, 'vgg_16.ckpt'),\n",
    "    slim.get_model_variables('vgg_16'))\n",
    "\n",
    "\n",
    "##########################\n",
    "# 4. 추론하기\n",
    "with tf.Session() as sess:\n",
    "    load_vars(sess)\n",
    "    network_input, probabilities = sess.run([processed_images,\n",
    "                                            probabilities])\n",
    "    probabilities = probabilities[0, 0:]\n",
    "    \n",
    "    names_ = imagenet.create_readable_names_for_imagenet_labels()\n",
    "    \n",
    "    idxs = np.argsort(-probabilities)[:5]\n",
    "    probs = probabilities[idxs]\n",
    "    classes = np.array(list(names_.values()))[idxs+1]\n",
    "    for c, p in zip(classes, probs):\n",
    "        print('Class: '+ c + '\\t|Prob: ' + str(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.5.5 정리\n",
    "\n",
    "이번 포스팅에서는 TF-Slim에 대해 살펴보았다. TF-Slim은 CNN 모델링에 있어서 간편하게 작성할 수 있도록 다양한 계층등을 추상화해서 제공하며, AlexNet, VGG, Inception 등 성능이 좋은 사전 학습된 모델들을 제공한다. TF-Slim에 대해 자세한 설명은 https://github.com/tensorflow/tensorflow/tree/r1.8/tensorflow/contrib/slim 에서 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
