{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chap08 - 큐, 스레드, 데이터 읽기\n",
    "\n",
    "> 텐서플로 파일 형식인 TFRecord를 읽고 쓰는 방법에 대해 알아보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1 입력 파이프라인\n",
    "\n",
    "MNIST 이미지처럼 용량이 크지 않은 데이터는 메모리에 올려 텐서플로(TensorFlow) 그래프에 데이터를 넣어주는 방법이 편리하지만, 데이터의 용량이 큰 경우에는 메모리에 데이터를 올리는 것이 어려워진다. 이럴 경우에는 데이터를 필요한 만큼 로드하는 방식이 효율적이다.\n",
    "\n",
    "앞에서 모델링한 딥러닝 모델에 데이터를 넣어주기 위해서 `tf.Session().run()`에서 `feed_dict`인자에 데이터를 넣어 줬었다. 하지만, 이러한 방법은 데이터를 단일 스레드로 복사하여 속도가 느리다는 단점이 있다.\n",
    "\n",
    "텐서플로에서는 이러한 단점을 보완하는 텐서플로의 표준 파일 형식과 이러한 형식을 인코딩/디코딩할 수 있는 기능 등이 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2 TFRecord\n",
    "\n",
    "텐서플로에서 기본 데이터 형식은 **TFRecord**이며, TFRecord는 이진 파일로 직렬화된 입력 데이터가 담겨있다. 이러한 직렬화는 **프로토콜 버퍼**(Protocol Buffer, protobuf)를 기반으로 하며, 프로토콜 버퍼는 데이터의 구조를 설명하는 스키마를 사용해 데이터를 저장용으로 변환하는 역할을 한다. 텐서플로에서는 원래의 데이터 파일을 사용하는 것보다 TFRecord를 사용하는 것이 더 효율적이다. \n",
    "\n",
    "- TFRecord 파일의 모든 데이터는 하나의 메모리 블록에 저장되므로, 파일이 개별로 저장된 입력 파일에 비해 메모리에서 데이터를 읽는 시간이 더 빠르다.\n",
    "- 텐서플로에서 TFRecord에 최적화된 기능들을 제공하고 있어, 멀티스레드 입력 파이프라인으로 사용하기에 더 적합하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2.1 TFRecordWriter로 쓰기\n",
    "\n",
    "TFRecord에 대해 알아보았으니, MNIST 데이터를 가지고 TFRecord 형식으로 변환해 보자. \n",
    "\n",
    "아래의 코드에서 `from tensorflow.contrib.learn.python.learn.datasets import mnist`의 `read_data_sets()`은  학습(train), 테스트(test), 검증(validation) 데이터가 분리(split)되어있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving train\n",
      "saving test\n",
      "saving validation\n",
      "train, test, validation TFRecords saved!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.learn.python.learn.datasets import mnist\n",
    "\n",
    "# mnist dataset 저장할 디렉터리\n",
    "save_dir = '../data/mnist'\n",
    "\n",
    "# save_dir에 MNIST 데이터 받기\n",
    "data_sets = mnist.read_data_sets(save_dir,\n",
    "                                 dtype=tf.uint8,\n",
    "                                 reshape=False,\n",
    "                                 validation_size=1000)\n",
    "\n",
    "\n",
    "data_splits = ['train', 'test', 'validation']\n",
    "for i, split in enumerate(data_splits):\n",
    "    print(\"saving %s\" % split)\n",
    "    data_set = data_sets[i]\n",
    "    \n",
    "    filename = os.path.join(save_dir, '%s.tfrecords' % split)\n",
    "    writer = tf.python_io.TFRecordWriter(filename)\n",
    "    for index in range(data_set.images.shape[0]):\n",
    "        image = data_set.images[index].tostring()\n",
    "        example = tf.train.Example(\n",
    "            features=tf.train.Features(feature={\n",
    "                'height': tf.train.Feature(\n",
    "                            int64_list=tf.train.Int64List(\n",
    "                                value=[data_set.images.shape[1]])),\n",
    "                'width': tf.train.Feature(\n",
    "                            int64_list=tf.train.Int64List(\n",
    "                                value=[data_set.images.shape[2]])),\n",
    "                'depth': tf.train.Feature(\n",
    "                            int64_list=tf.train.Int64List(\n",
    "                                value=[data_set.images.shape[3]])),\n",
    "                'label': tf.train.Feature(\n",
    "                            int64_list=tf.train.Int64List(\n",
    "                                value=[int(data_set.labels[index])])),\n",
    "                'image_raw': tf.train.Feature(\n",
    "                                bytes_list=tf.train.BytesList(\n",
    "                                    value=[image]))\n",
    "            }))\n",
    "    writer.write(example.SerializeToString())\n",
    "writer.close()\n",
    "\n",
    "print('train, test, validation TFRecords saved!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 코드를 하나씩 살펴보도록 하자.\n",
    "\n",
    "먼저 `tf.python_io.TFRecordWriter()`를 이용해 각 데이터 스플릿에 해당하는 파일명을 지정해 줬ㄷ. \n",
    "\n",
    "```python\n",
    "filename = os.path.join(save_dir, '%s.tfrecords' % split)\n",
    "writer = tf.python_io.TFRecordWriter(filename)\n",
    "```\n",
    "\n",
    "그다음, 각 이미지에 대해 NumPy의 `array`를 byte string으로 변환한다.\n",
    "\n",
    "```python\n",
    "image = data_set.images[index].tostring()\n",
    "```\n",
    "\n",
    "이렇게 변환된 이미지를 프로토콜 버퍼 형식으로 변환한다. 위의 코드에서 `tf.train.Example`이 데이터를 저장하는 자료구조이다. `Example`객체 안에 `tf.train.Features` 객체를 포함하고 있는데, `Features` 객체는 `tf.trin.Feature`를 포함하고 있으며, `Feature`는 `tf.train.Int64List, BytesList, FloatList`등을 포함할 수 있다. 아래의 코드는 MNIST 이미지의 레이블을 인코딩하는 코드이다.\n",
    "\n",
    "```python\n",
    "tf.train.Feature(\n",
    "    int64_list=tf.train.Int64List(\n",
    "        value=[int(data_set.labels[index])]))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TFRecordWriter`를 이용해 저장된 데이터가 어떠한 형태인지 `tf.python_io.tf_record_iterator`를 사용해 알아보자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\n\\xe8\\x06\\n\\x0e\\n\\x05depth\\x12\\x05\\x1a\\x03\\n\\x01\\x01\\n'\n"
     ]
    }
   ],
   "source": [
    "filname = os.path.join(save_dir, 'train.tfrecords')\n",
    "record_iterator = tf.python_io.tf_record_iterator(filename)\n",
    "serialized_img_example = next(record_iterator)\n",
    "print(serialized_img_example[:20])  # 일부만 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 출력결과에서 확인할 수 있듯이 저장된 데이터의 형태는 바이트 스트링이다. 이러한 바이트 스트링의 형태를 NumPy의 배열로 복구하려면 `ParseFromString()`을 이용하면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "example = tf.train.Example()\n",
    "example.ParseFromString(serialized_img_example)\n",
    "image = example.features.feature['image_raw'].bytes_list.value\n",
    "label = example.features.feature['label'].int64_list.value[0]\n",
    "width = example.features.feature['width'].int64_list.value[0]\n",
    "height = example.features.feature['height'].int64_list.value[0]\n",
    "depth = example.features.feature['depth'].int64_list.value[0]\n",
    "\n",
    "img_flat = np.frombuffer(image[0], dtype=np.uint8)\n",
    "img_reshape = img_flat.reshape([height, width, depth])\n",
    "img_plt = img_flat.reshape([height, width])\n",
    "\n",
    "plt.imshow(img_plt, 'gray')\n",
    "plt.xticks([]), plt.yticks([]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.3 큐(Queue)\n",
    "\n",
    "텐서플로 큐(Queue)는 우리가 알고있는 큐와 같은 역할을 하지만 가장 큰 차이는 텐서플로의 큐는 연산 그래프의 일부분이라는 것이다. \n",
    "\n",
    "다음 예제들을 통해 텐서플로의 큐에대해 알아보도록 하자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3.1 큐에 넣고 빼기\n",
    "\n",
    "아래의 예제코드는 최대 10개의 항목을 넣을 수 있는 스트링(string)의 FIFO(First In First Out) 큐를 만들어 본다. 텐서플로의 큐는 연산 그래프의 일부이므로 세션(`tf.Session()`)안에서 수행된다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "queue1 = tf.FIFOQueue(capacity=10, dtypes=[tf.string])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 코드에서 `queue1`에서 텐서플로 내부적으로 10개의 항목을 저장하기 위한 메모리 버퍼가 생성된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### enqueue()\n",
    "\n",
    "생성된 `FIFOQueue`에 `enqueue()`를 이용해 항목을 추가해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "연산을 실행하기 전 queue1.size() : 0\n",
      "연산을 실행한 후 queue1.size() : 1\n"
     ]
    }
   ],
   "source": [
    "enque_op = queue1.enqueue(['F'])\n",
    "print('연산을 실행하기 전 queue1.size() :', sess.run(queue1.size()))\n",
    "\n",
    "enque_op.run()\n",
    "print('연산을 실행한 후 queue1.size() :', sess.run(queue1.size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "연산을 실행한 후 queue1.size() : 4\n"
     ]
    }
   ],
   "source": [
    "enque_op = queue1.enqueue(['I'])\n",
    "enque_op.run()\n",
    "enque_op = queue1.enqueue(['F'])\n",
    "enque_op.run()\n",
    "enque_op = queue1.enqueue(['O'])\n",
    "enque_op.run()\n",
    "\n",
    "queue1_size = sess.run(queue1.size())\n",
    "print('연산을 실행한 후 queue1.size() :', queue1_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dequeue()\n",
    "\n",
    "이번에는 `dequeue()`를 이용해 `FIFOQueue`에서 항목을 제거해보자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 번째 출력 b'F'\n",
      "2 번째 출력 b'I'\n",
      "3 번째 출력 b'F'\n",
      "4 번째 출력 b'O'\n"
     ]
    }
   ],
   "source": [
    "x = queue1.dequeue()\n",
    "\n",
    "for i in range(1, queue1_size+1):\n",
    "    print('%d 번째 출력 %s' % (i, x.eval()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3.2 멀티스레딩\n",
    "\n",
    "텐서플로 세션(`tf.Session()`)은 기본적으로 멀티스레드(Multi-Thread)로 실행되며, 여러개의 스레드가 같은 세션을 사용하여 병렬로 연산을 실행한다. \n",
    "\n",
    "간단한 샘플 데이터를 이용해 텐서플로의 스레딩 및 스레드와 큐의 상호작용을 살펴보고 난뒤에 MNIST 데이터를 이용해 멀티스레딩을 적용해보도록 하자.\n",
    "\n",
    "먼저 100개의 항목을 가진 `tf.FIFOQueue`를 생성한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threads:\n",
      "[<Thread(Thread-6, initial)>,\n",
      " <Thread(Thread-7, initial)>,\n",
      " <Thread(Thread-8, initial)>,\n",
      " <Thread(Thread-9, initial)>,\n",
      " <Thread(Thread-10, initial)>,\n",
      " <Thread(Thread-11, initial)>,\n",
      " <Thread(Thread-12, initial)>,\n",
      " <Thread(Thread-13, initial)>,\n",
      " <Thread(Thread-14, initial)>,\n",
      " <Thread(Thread-15, initial)>]\n",
      "==============================\n",
      "check queue.size():\n",
      "17\n",
      "100\n",
      "100\n",
      "==============================\n",
      "queue.dequeue_many(10):\n",
      "[ 0.88396263  0.14378338 -0.98043966 -1.2009127   0.27303845 -0.8871811\n",
      "  1.4003232   0.15166609  0.9299293  -1.6246831 ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import threading\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from pprint import pprint\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# FIFOQueue에 넣을 데이터 생성: -0.81226367과 같이 하나의 값만 출력됨\n",
    "gen_random_normal = tf.random_normal(shape=()) \n",
    "# FIFOQueue 정의\n",
    "queue = tf.FIFOQueue(capacity=100, dtypes=[tf.float32], shapes=())\n",
    "enque = queue.enqueue(gen_random_normal)\n",
    "\n",
    "# sess.run()을 여러번 호출하여\n",
    "# FIFOQueue에 10개의 아이템을 더하는 함수\n",
    "def add():\n",
    "    for i in range(10):\n",
    "        sess.run(enque)\n",
    "\n",
    "# 10개의 스레드를 생성\n",
    "threads = [threading.Thread(target=add, args=()) for i in range(10)]\n",
    "\n",
    "print('threads:')\n",
    "pprint(threads)\n",
    "\n",
    "# FIFOQueue 의 크기가 100이 될때까지 확인\n",
    "for t in threads:\n",
    "    t.start()\n",
    "    \n",
    "print('='*30)\n",
    "print('check queue.size():')\n",
    "print(sess.run(queue.size()))\n",
    "time.sleep(0.003)\n",
    "print(sess.run(queue.size()))\n",
    "time.sleep(0.003)\n",
    "print(sess.run(queue.size()))\n",
    "\n",
    "# dequeue_many()를 이용해 10개 아이템 출력\n",
    "x = queue.dequeue_many(10)\n",
    "print('='*30)\n",
    "print('queue.dequeue_many(10):')\n",
    "print(x.eval())\n",
    "sess.run(queue.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3.3 Coordinator와 QueueRunner\n",
    "\n",
    "위에서 생성한 샘플 데이터가 아닌 실제 데이터에서 멀티스레드를 제대로 동작하게 하는 것은 복잡하다. 예를 들어, 스레드가 중단된 후에는 큐가 닫혀야한다. \n",
    "\n",
    "텐서플로는 스레드 셋의 종료를 조정하는 `tf.train.Coordinator`와 데이터를 큐에 넣을 수 있도록 여러개의 스레드를 가져오는 역할을 하는 `tf.train.QueueRunner`를 제공한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tf.train.Coordinator\n",
    "\n",
    "`tf.train.Coordinator`의 사용법을 8.3.2에서 처럼 간단한 샘플 데이터를 이용해 알아보자.\n",
    "\n",
    "어떠한 스레드이건 상관없이 `tf.train.Coordinator`의 `request_stop()`을 통해 모든 스레드를 중단할 수 있다. `tf.train.Coordinator`의 `should_stop()`을 이용해 스레드를 중단할지의 여부를 확인할 수 있다. \n",
    "\n",
    "아래의 예제는 `add()`함수에 스레드의 인덱스 `i`를 전달하고 `i==11`일 경우 스레드를 중단하도록 설정하였다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threads:\n",
      "[<Thread(Thread-6, initial)>,\n",
      " <Thread(Thread-7, initial)>,\n",
      " <Thread(Thread-8, initial)>,\n",
      " <Thread(Thread-9, initial)>,\n",
      " <Thread(Thread-10, initial)>,\n",
      " <Thread(Thread-11, initial)>,\n",
      " <Thread(Thread-12, initial)>,\n",
      " <Thread(Thread-13, initial)>,\n",
      " <Thread(Thread-14, initial)>,\n",
      " <Thread(Thread-15, initial)>]\n",
      "==============================\n",
      "check queue.size():\n",
      "29\n",
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from pprint import pprint\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# FIFOQueue에 넣을 데이터 생성: -0.81226367과 같이 하나의 값만 출력됨\n",
    "gen_random_normal = tf.random_normal(shape=()) \n",
    "# FIFOQueue 정의\n",
    "queue = tf.FIFOQueue(capacity=100, dtypes=[tf.float32], shapes=())\n",
    "enque = queue.enqueue(gen_random_normal)\n",
    "\n",
    "# sess.run()을 여러번 호출하여\n",
    "# FIFOQueue에 10개의 아이템을 더하는 함수\n",
    "# i==11 일 경우 스레드를 중지한다.\n",
    "def add(coord, i):\n",
    "    while not coord.should_stop():\n",
    "        sess.run(enque)\n",
    "        if i == 11:\n",
    "            coord.request_stop()\n",
    "\n",
    "# 10개의 스레드를 생성\n",
    "coord = tf.train.Coordinator()\n",
    "threads = [threading.Thread(target=add, args=(coord, i)) for i in range(10)]\n",
    "coord.join(threads)\n",
    "\n",
    "print('threads:')\n",
    "pprint(threads)\n",
    "\n",
    "# FIFOQueue 의 크기가 100이 될때까지 확인\n",
    "for t in threads:\n",
    "    t.start()\n",
    "    \n",
    "print('='*30)\n",
    "print('check queue.size():')\n",
    "print(sess.run(queue.size()))\n",
    "time.sleep(0.005)\n",
    "print(sess.run(queue.size()))\n",
    "time.sleep(0.005)\n",
    "print(sess.run(queue.size()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tf.train.QueueRunner와 tf.RandomShuffleQueue\n",
    "\n",
    "위의 예제에서는 Python의 `threading`모듈을 이용해 멀티스레드를 구현했지만, 텐서플로에서 제공하는 `tf.train.QueueRunner`를 사용하는 것이 더 낫다. 그 이유는 위의 예제와 동일한 작업을 수행하면서 예외 상황에서는 큐를 닫아준다. \n",
    "\n",
    "`tf.RandomShuffleQueue`는 항목을 랜덤하게 꺼내는 큐이며, 데이터의 순서를 섞을 필요가 있는 경사 하강법같은 최적화 함수를 사용해 모델을 학습시킬 때 사용할 수 있다. `tf.RandomShuffleQueue`의 `min_after_dequeue` 인자는 `dequeue` 후에 큐에 남아 있을 아이템의 최소개수를 설정하는 인자이다.\n",
    "\n",
    "아래의 예제코드는 위의 예제를 `tf.train.QueueRunner`와 `tf.RandomShuffleQueue`를 사용해 구현한 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "check queue.size():\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'QueueRunner' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-acf448d883d5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'='\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'check queue.size():'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mqr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.005\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mqr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'QueueRunner' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from pprint import pprint\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# RandomShuffleQueue 넣을 데이터 생성: -0.81226367과 같이 하나의 값만 출력됨\n",
    "gen_random_normal = tf.random_normal(shape=()) \n",
    "# RandomShuffleQueue 정의\n",
    "queue = tf.RandomShuffleQueue(capacity=100, dtypes=[tf.float32],\n",
    "                              min_after_dequeue=1)\n",
    "enqueue_op = queue.enqueue(gen_random_normal)\n",
    "\n",
    "# QueueRunner를 이용한 멀티스레드 구현\n",
    "qr = tf.train.QueueRunner(queue, [enqueue_op] * 10)\n",
    "coord = tf.train.Coordinator()\n",
    "enqueue_threads = qr.create_threads(sess, coord=coord, start=True)\n",
    "coord.request_stop()\n",
    "coord.join(enqueue_threads)\n",
    "\n",
    "print('='*30)\n",
    "print('check queue.size():')\n",
    "print(sess.run(queue.size()))\n",
    "time.sleep(0.005)\n",
    "print(sess.run(queue.size()))\n",
    "time.sleep(0.005)\n",
    "print(sess.run(queue.size()))\n",
    "\n",
    "print(sess.run(queue.size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
