{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chap05 - 텍스트 1: 텍스트와 시퀀스 처리 및 텐서보드 시각화\n",
    "\n",
    "> 텐서플로에서 시퀀스(sequence) 데이터인 텍스트를 어떻게 다루는지 알아보고, RNN 구현방법 및 텐서보드를 이용한 시각화에 대해 알아본다. 그 다음 단어 임베딩 학습 및 LSTM을 구현해본다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 시퀀스 데이터의 중요성\n",
    "\n",
    "[Chap04-합성곱 신경망 CNN](http://excelsior-cjh.tistory.com/152)에서 이미지의 공간(spatial) 구조를 이용하여 CNN을 구현하였고, 이러한 구조를 활용하는 것이 중요하다는 것을 알아 보았다. 이번에 알아볼 순차형 데이터 구조인 시퀀스(sequence) 데이터 또한 중요하고 유용한 구조이다. 시퀀스 데이터란 각각의 데이터가 순서가 있는 데이터를 말하며, 다양한 분야에서 찾을 수가 있다. 예를 들어, 음성신호, 텍스트, 주가 데이터 등이 있다.\n",
    "\n",
    "<img src=\"./images/sequence_data.png\" width=\"60%\" height=\"60%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 RNN 소개\n",
    "\n",
    "**RNN(순환신경망, Recurrent Neural Network)**은 시퀀스 데이터의 모델링에 사용되는 신경망 구조이다. RNN 모델의 바탕에는 시퀀스에서 현재 이후의 각 데이터는 새로운 정보를 제공하므로, 이 정보로 모델의 현재 상태를 **'갱신(업데이트)'** 한다는 아이디어가 깔려있다.\n",
    "\n",
    "어떤 텍스트에서 문장을 읽을 때 각각의 새로운 단어로 현재 상태의 정보가 갱신되는데 이 상태는 새롭게 나타난 단어뿐만 아니라 이전의 단어에 대해서도 종속적이다.\n",
    "\n",
    "머신러닝에서 시퀀스 패턴의 데이터를 모델링하기 위해 흔히 사용되는 통계 및 확률기반의 [마르코프 체인](https://en.wikipedia.org/wiki/Markov_chain)(Markov Chain) 모델이다. 데이터를 시퀀스를 '체인'으로 본다면, 체인의 각 노드는 이전 노드로부터 어떤 식으로든 종속적이므로 '과거'는 지워지지 않고 이어진다.\n",
    "\n",
    "RNN 모델 또한 체인 구조 개념을 기반으로 하고 있으며 정보를 유지하고 갱신하는 방법에 따라 다양한 종류가 있다. '순환'이라는 이름에서 알 수 있듯이 RNN은 일종의 **'루프'**로 이루어진다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/rnn03.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 그림에서 볼 수 있듯이, 시점 $t$에서 네트워크는 입력값 $x_t$ (문장 중 하나의 단어)를 관찰하고, '상태 벡터'(state vector, $t$ 시점의 출력)를 이전의 $h_{t-1}$에서 $h_t$로 업데이트 한다. 새로운 입력(다음 단어)은 $t-1, t-2, \\dots$에서 관찰한 이전 입력이 현재($t$) 입력의 이해에 영향을 미치므로 과거 시퀀스에 종속적이다. 위의 그림에서 처럼, 이러한 순환구조를 길게 펼쳐놓은 체인으로 생각할 수 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.1 기본적인 RNN 구현\n",
    "\n",
    "이제 텐서플로(TensorFlow)를 사용해 시퀀스 데이터를 다루는 방법과 기초적인 RNN을 구현해보도록 하자.\n",
    "\n",
    "먼저, RNN 모델의 업데이트 단계에 대해 알아보면 RNN의 업데이트 단계는 다음과 같이 나타낼 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/rnn02.png\" width=\"70%\" height=\"70%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이를 수식으로 나타내면 아래와 같다.\n",
    "\n",
    "$$\n",
    "h_t = \\tanh{\\left( \\mathrm{W}_x x_t + \\mathrm{W}_h h_{t-1} + b \\right)}\n",
    "$$\n",
    "\n",
    "$\\mathrm{W}_x, \\mathrm{W}_h, b$ 는 학습할 가중치(weight) 및 편향값(bias)의 변수이며, 활성화 함수로는 하이퍼볼릭 탄젠트 함수($\\tanh$)를 사용했다. $x_t$와 $h_t$는 입력과 상태 벡터이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 시퀀스로서의 MNIST 이미지\n",
    "\n",
    "텍스트 데이터 적용에 앞서, 익숙한 데이터인 MNIST 이미지 분류를 RNN 모델을 구현하여 분류 작업을 수행해보자. \n",
    "\n",
    "[Chap04-합성곱 신경망 CNN](http://excelsior-cjh.tistory.com/152)에서 살펴볼 수 있듯이 CNN은 이미지의 공간(spatial) 구조를 활용한다. 이미지 구조는 CNN 모델에 적합하지만, 인접한 영역의 픽셀은 서로 연관되어 있으므로 이를 시퀀스 데이터로 볼 수도 있다.\n",
    "\n",
    "아래의 그림처럼 MNIST 데이터에서 `28 x 28` 픽셀을 시퀀스의 각원소는 `28`개의 픽셀을 가진 길이가 `28` 시퀀스 데이터로 볼 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/mnist_seq.png\" width=\"70%\" height=\"70%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "먼저 데이터를 읽어 들이고 매개변수 정의 및 데이터에 사용할 플레이스홀더를 만들어 준다. MNIST데이터를 불러오는 방법은 교재와는 다르다. 그 이유는 블로그 포스팅 시점인 2018.06.13(수)의 `tensorflow` 버전이 1.8인데 해당 버전에서 아래와 같이 MNIST데이터를 불러오면 Warning이 나타난다.\n",
    "\n",
    "```python\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"../data\", one_hot=True)\n",
    "```\n",
    "```bash\n",
    "WARNING:tensorflow:From <ipython-input-1-40ec958cfe79>:3: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
    "```\n",
    "\n",
    "이를 방지하기 위해 `tf.keras.datasets.mnist.load_data()`를 사용해서 MNIST데이터를 불러온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "#####################\n",
    "# Define Parameters #\n",
    "#####################\n",
    "element_size = 28\n",
    "time_steps = 28\n",
    "num_classes = 10\n",
    "batch_size = 128\n",
    "hidden_layer_size = 128\n",
    "\n",
    "# Where to save TensorBoard model summaries\n",
    "LOG_DIR = \"./logs/RNN_with_summaries\"\n",
    "\n",
    "\n",
    "# MNIST 데이터 불러오기 위한 함수 정의\n",
    "def mnist_load():\n",
    "    (train_x, train_y), (test_x, test_y) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "    # Train set\n",
    "    train_x = train_x.astype('float32') / 255.\n",
    "    train_y = tf.keras.utils.to_categorical(train_y, num_classes=10)\n",
    "    # Test set\n",
    "    test_x = test_x.astype('float32') / 255.\n",
    "    test_y = tf.keras.utils.to_categorical(test_y, num_classes=10)\n",
    "    \n",
    "    return (train_x, train_y), (test_x, test_y)\n",
    "\n",
    "# MNIST 데이터 불러오기\n",
    "(train_x, train_y), (test_x, test_y) = mnist_load()\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(({\"image\": train_x}, train_y))\n",
    "dataset = dataset.shuffle(100000).repeat().batch(batch_size)\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "next_batch = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create placeholders for inputs, labels\n",
    "_inputs = tf.placeholder(tf.float32, \n",
    "                         shape=[None, time_steps, element_size], \n",
    "                         name='inputs')\n",
    "y = tf.placeholder(tf.float32, shape=[None, num_classes], name='labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "코드에서 각 파라미터들의 설명은 다음과 같다.\n",
    "\n",
    "- `element_size` : 시퀀스 벡터 각각의 차원이며, 행 또는 열의 픽셀 크기인 28.\n",
    "- `time_steps` : 한 시퀀스 내에 들어 있는 원소의 수.\n",
    "- RNN 학습 단계에서 데이터를 입력해 줄때 `[batch_size, time_steps, element_size]`로 `reshape()` 해준다. \n",
    "- `hidden_layer_size` : 128로 설정하고 RNN의 출력 벡터(상태 벡터, state vector)의 크기를 의미한다.\n",
    "- `LOG_DIR` : 텐서보드(TensorBoard) 시각화를 위해 모델의 요약 정보를 저장하는 디렉터리이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RNN 단계\n",
    "\n",
    "RNN 모델 구현에 앞서 다음과 같이 텐서보드(TensorBoard)에서 모델과 학습과정을 시각화 하는데 사용할 요약을 기록하는 함수를 만들어 준다. 아래의 코드는 [tensorflow.org](https://www.tensorflow.org/programmers_guide/summaries_and_tensorboard)에서 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 요약(summaries)을 로깅(logging)하는 몇몇 연산을 추가하는 헬퍼 함수\n",
    "def variable_summaries(var):\n",
    "    with tf.name_scope('summaries'):\n",
    "        mean = tf.reduce_mean(var)\n",
    "        tf.summary.scalar('mean', mean)\n",
    "        with tf.name_scope('stddev'):\n",
    "            stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n",
    "        tf.summary.scalar('stddev', stddev)\n",
    "        tf.summary.scalar('max', tf.reduce_max(var))\n",
    "        tf.summary.scalar('min', tf.reduce_min(var))\n",
    "        tf.summary.histogram('histogram', var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음으로 RNN 에서 사용할 가중치와 편향값 변수를 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights and bias for input and hidden layer\n",
    "with tf.name_scope('rnn_weights'):\n",
    "    with tf.name_scope('W_x'):\n",
    "        Wx = tf.Variable(tf.zeros([element_size, hidden_layer_size]))\n",
    "        variable_summaries(Wx)\n",
    "    with tf.name_scope('W_h'):\n",
    "        Wh = tf.Variable(tf.zeros([hidden_layer_size, hidden_layer_size]))\n",
    "        variable_summaries(Wh)\n",
    "    with tf.name_scope('Bias'):\n",
    "        b_rnn = tf.Variable(tf.zeros([hidden_layer_size]))\n",
    "        variable_summaries(b_rnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `tf.scan()`으로 RNN 단계 적용\n",
    "\n",
    "위에서 만든 변수들을 이용해 RNN 단계를 구현하는 함수를 만들어 준다. 아래의 `rnn_step()`함수는 다음 수식 부분을 구현한 것이다.\n",
    "\n",
    "$$\n",
    "h_t = \\tanh{\\left( \\mathrm{W}_x x_t + \\mathrm{W}_h h_{t-1} + b \\right)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_step(previous_hidden_state, x):\n",
    "    current_hidden_state = tf.tanh(\n",
    "            tf.matmul(previous_hidden_state, Wh) + \n",
    "            tf.matmul(x, Wx) + b_rnn)\n",
    "    return current_hidden_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그런다음 위의 함수를 이용해 28 단계의 스텝에 걸쳐 적용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.scan() 함수로 입력값 처리\n",
    "# input shape: (batch_size, time_steps, element_size)\n",
    "processed_input = tf.transpose(_inputs, perm=[1, 0, 2])\n",
    "# transposed input shape: (time_steps, batch_size, element_size)\n",
    "\n",
    "initial_hidden = tf.zeros([batch_size, hidden_layer_size])\n",
    "# time_steps에 따른 상태 벡터(state vector) 구하기\n",
    "all_hidden_states = tf.scan(rnn_step, processed_input,\n",
    "                            initializer=initial_hidden, name='states')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 코드에서 `_input`의 형태(`shape`)를 `tf.transpose()`를 이용해 `[batch_size, time_steps, element_size]` → `[time_steps, batch_size, element_size]`로 바꿔 주었다. `tf.transpose()`에서 `perm=`인자는 변경할 축을 지정한다. 그 다음 `tf.scan()`함수를 이용하여 시간 단계(time step)를 반복할 수 있다. `tf.scan()`함수는 순서대로 모든 원소의 시퀀스에 반복해서 호출 가능한 객체(함수)를 적용한다. 자세한 내용은 [tensorflow.org#tf.scan](https://www.tensorflow.org/api_docs/python/tf/scan)에서 확인할 수 있다. 아래의 예제는 `tf.scan()`함수에 대한 예제를 보여주며, RNN 구현에 필요한 코드는 관련이 없는 코드이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'T', b'Te', b'Ten', b'Tens', b'Tenso', b'Tensor', b'Tensor ',\n",
       "       b'Tensor F', b'Tensor Fl', b'Tensor Flo', b'Tensor Flow'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tf.scan() 예제\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "elems = np.array(['T', 'e', 'n', 's', 'o', 'r', ' ', 'F', 'l', 'o', 'w'])\n",
    "scan_sum = tf.scan(lambda a, x: a + x, elems)\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(scan_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 시퀀스 출력\n",
    "\n",
    "5.2.1 첫 부분에 RNN 구조 그림에서 보았듯이, RNN에서는 각 시간 단계에 대한 상태 벡터($h_t$, state vector)에 가중치를 곱하여 데이터의 새로운 표현인 출력 벡터를 얻는다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 출력에 적용할 가중치\n",
    "with tf.name_scope('linear_layer_weights') as scope:\n",
    "    with tf.name_scope('W_linear'):\n",
    "        Wl = tf.Variable(tf.truncated_normal([hidden_layer_size, num_classes], \n",
    "                                             mean=0, stddev=.01))\n",
    "        variable_summaries(Wl)\n",
    "    with tf.name_scope('Bias_linear'):\n",
    "        bl = tf.Variable(tf.truncated_normal([num_classes], \n",
    "                                             mean=0, stddev=.01))\n",
    "        variable_summaries(bl)\n",
    "        \n",
    "# 상태 벡터에 linear layer 적용\n",
    "def get_linear_layer(hidden_state):\n",
    "    return tf.matmul(hidden_state, Wl) + bl\n",
    "\n",
    "with tf.name_scope('linear_layer_weights') as scope:\n",
    "    # 시간에 따라 반복하면서 모든 RNN 결과에 get_linear_layer 적용\n",
    "    all_outputs = tf.map_fn(get_linear_layer, all_hidden_states)\n",
    "    # 최종 결과 = h_28\n",
    "    output = all_outputs[-1]\n",
    "    tf.summary.histogram('outputs', output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN의 입력은 연속적이며 출력 또한 마찬가지다. 위에서 `output`는 전체 시퀀스를 표현하는 **누적된** 정보를 가지고 있다고 가정한다. `tf.map_fn()`은 파이썬 내장함수인 `map()`과 유사한 기능을 가진 함수이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RNN 분류\n",
    "\n",
    "RNN 모델 구성이 끝났으므로 학습에 필요한 손실함수, 최적화, 예측을 위한 연산을 정의하고, 텐서보드에 사용할 요약(summary)를 추가 해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('cross_entropy'):\n",
    "    cross_entropy = tf.reduce_mean(\n",
    "            tf.nn.softmax_cross_entropy_with_logits_v2(logits=output, labels=y))\n",
    "    tf.summary.scalar('cross_entropy', cross_entropy)\n",
    "    \n",
    "with tf.name_scope('train'):\n",
    "    # RMSPropOptimizer 사용\n",
    "    train_step = tf.train.RMSPropOptimizer(0.001, 0.9).minimize(cross_entropy)\n",
    "    \n",
    "with tf.name_scope('accuracy'):\n",
    "    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(output, 1))\n",
    "    accuracy = (tf.reduce_mean(tf.cast(correct_prediction, tf.float32)))*100\n",
    "    tf.summary.scalar('accuracy', accuracy)\n",
    "    \n",
    "# 요약을 병합\n",
    "merged = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음으로, 테스트 셋에서 `batch_size`만큼 추출하여 작은 테스트 데이터를 생성하고 텐서보드에 사용할 로깅을 기록하기 위해 추가해 주고 학습을 수행 해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 1000\t MiniBatch Loss: 1.084150\t Training Acc=58.59375\n",
      "Iter: 2000\t MiniBatch Loss: 0.577252\t Training Acc=82.03125\n",
      "Iter: 3000\t MiniBatch Loss: 0.279067\t Training Acc=90.62500\n",
      "Iter: 4000\t MiniBatch Loss: 0.154536\t Training Acc=97.65625\n",
      "Iter: 5000\t MiniBatch Loss: 0.128562\t Training Acc=97.65625\n",
      "Iter: 6000\t MiniBatch Loss: 0.044278\t Training Acc=98.43750\n",
      "Iter: 7000\t MiniBatch Loss: 0.083056\t Training Acc=99.21875\n",
      "Iter: 8000\t MiniBatch Loss: 0.063170\t Training Acc=98.43750\n",
      "Iter: 9000\t MiniBatch Loss: 0.019528\t Training Acc=100.00000\n",
      "Iter: 10000\t MiniBatch Loss: 0.077181\t Training Acc=99.21875\n",
      "Test Accuracy: 96.09375\n"
     ]
    }
   ],
   "source": [
    "# Get a small test set\n",
    "test_data = test_x[:batch_size].reshape([-1, time_steps, element_size])\n",
    "test_label = test_y[:batch_size]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # LOG_DIR에 텐세보드에서 사용할 요약을 기록\n",
    "    train_writer = tf.summary.FileWriter(LOG_DIR + '/train', \n",
    "                                         graph=tf.get_default_graph())\n",
    "    test_writer = tf.summary.FileWriter(LOG_DIR + '/test', \n",
    "                                        graph=tf.get_default_graph())\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "        \n",
    "    for step in range(10000):\n",
    "        batch_x, batch_y = sess.run(next_batch)\n",
    "        summary, _ = sess.run([merged, train_step], \n",
    "                              feed_dict={_inputs:batch_x['image'], y:batch_y})          \n",
    "        # 요약 추가\n",
    "        train_writer.add_summary(summary, step)\n",
    "         \n",
    "        if (step+1) % 1000 == 0:\n",
    "            acc, loss = sess.run([accuracy, cross_entropy], \n",
    "                                 feed_dict={_inputs:batch_x['image'], y:batch_y})\n",
    "            print(\"Iter: %04d\\t\" % (step+1), \n",
    "                  \"MiniBatch Loss: {:.6f}\\t\".format(loss),\n",
    "                  \"Training Acc={:.5f}\".format(acc))\n",
    "\n",
    "        if (step+1) % 100 == 0:\n",
    "            # MNIST 테스트 이미지에서 정확도를 계산해 요약에 추가\n",
    "            summary, acc = sess.run([merged, accuracy], \n",
    "                                    feed_dict={_inputs: test_data, \n",
    "                                               y: test_label})\n",
    "            test_writer.add_summary(summary, step)\n",
    "\n",
    "                \n",
    "    test_acc = sess.run(accuracy, feed_dict={_inputs: test_data,\n",
    "                                             y: test_label})\n",
    "    print(\"Test Accuracy:\", test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 텐서보드로 모델 시각화하기\n",
    "\n",
    "이제 학습한 RNN 모델을 텐서보드에서 확인 해보자. 텐서보드를 사용하려면 Windows 같은 경우 cmd이며, Mac/Linux 인 경우 Terminal에서 아래의 명령어를 입력하면 된다.\n",
    "\n",
    "```bash\n",
    "# LOG_DIR: 지정한 로깅 디렉터리\n",
    "# 위의 예시에서는 ./logs/RNN_with_summaries 로 지정해줌  \n",
    "tensorboard --logdir=LOG_DIR\n",
    "```\n",
    "\n",
    "위의 명령어를 실행하면 입력할 URL 주소를 다음과 같이 알려준다. \n",
    "\n",
    "<img src=\"./images/tensorboard.png\" width=\"95%\" height=\"95%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 해당 주소(대부분 `localhost:6006` 이다)로 이동하면 다음과 같은 그림을 볼 수 있다. 먼저, **SCALARS** 탭에서는 학습 및 테스트 정확도뿐만 아니라 변수에 관한 요약통계 등 모든 스칼라 요약 데이터를 확인할 수 있다.\n",
    "\n",
    "![](./images/tb02.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GRAPHS** 탭에서는 그래프의 시각화를 통해 연산 그래프를 볼 수 있다.\n",
    "\n",
    "![](./images/tb03.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**HISTOGRAMS** 탭에서는 학습 과정에서의 가중치의 값을 히스토그램으로 볼 수 있다. 이러한 히스토그램을 보기 위해서는 코드에서 `tf.summary.histgram()`을 추가해줘야 한다.\n",
    "\n",
    "![](./images/tb04.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.2 텐서플로 내장 RNN 기능\n",
    "\n",
    "5.2.1에서는 Low-Level 텐서플로를 이용하여 기본적인 RNN 모델을 구성해 보았다. 이번에는 High-Level인 [`tf.nn.rnn_cell.BasicRNNCell`](https://www.tensorflow.org/api_docs/python/tf/nn/rnn_cell)과 [`tf.nn.dynamic_rnn()`](https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn)을 이용해 짧고 쉬운 RNN 모델을 구현해 보도록하자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "element_size = 28 \n",
    "time_steps = 28\n",
    "num_classes = 10\n",
    "batch_size = 128\n",
    "hidden_layer_size = 128\n",
    "\n",
    "# 1) Create placeholders for inputs, labels\n",
    "_inputs = tf.placeholder(tf.float32, shape=[None, time_steps,\n",
    "                                            element_size, name='inputs'])\n",
    "y = tf.placeholder(tf.float32, shape=[None, num_classes], name='inputs')\n",
    "\n",
    "# 2) RNN Model\n",
    "# Tensorflow built-in functions\n",
    "run_cell = tf.nn.rnn_cell.BasicRNNCell(hidden_layer_size)\n",
    "outputs, _ = tf.nn.dynamic_rnn(rnn_cell, _inputs, dtype=tf.float32)\n",
    "\n",
    "Wl = tf.Variable(tf.truncated_normal([hidden_layer_size, num_classes],\n",
    "                                     mean=0, stddev=.01))\n",
    "bl = tf.Variable(tf.truncated_normal([num_classes], mean=0, stddev=.01))\n",
    "\n",
    "def get_linear_layer(vector):\n",
    "    return tf.matmul(vector, Wl) + bl\n",
    "\n",
    "last_rnn_output = outputs[:, -1, :]\n",
    "final_output = get_linear_layer(last_rnn_output)\n",
    "\n",
    "# 3) Loss function\n",
    "cross_entropy = tf.reduce_mean(\n",
    "                    tf.nn.softmax_cross_entropy_with_logits_v2(logits=final_output, labels=y))\n",
    "# 4) Optimizer\n",
    "train_step = tf.train.RMSPropOptimizer(0.001, 0.9).minimize(cross_entropy)\n",
    "\n",
    "# 5) accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(final_output, 1))\n",
    "accuracy = (tf.reduce_mean(tf.cast(correct_prediction, tf.float32)))*100\n",
    "\n",
    "# 6) Training\n",
    "with tf.InteractiveSession() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Get a small test set\n",
    "    test_data = test_x[:batch_size].reshape([-1, time_steps, element_size])\n",
    "    test_label = test_y[:batch_size]\n",
    "    \n",
    "    for step in range(3001):"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
