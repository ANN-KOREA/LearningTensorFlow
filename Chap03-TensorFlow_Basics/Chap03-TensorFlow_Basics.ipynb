{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chap03 - 텐서플로의 기본 이해하기\n",
    "\n",
    "텐서플로의 핵심 구축 및 동작원리를 이해하고, 그래프를 만들고 관리하는 방법과 상수, 플레이스홀더, 변수 등 텐서플로의 '구성 요소'에 대해 알아보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 연산 그래프"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 연산 그래프란?\n",
    "\n",
    "그래프는 아래의 그림과 같이 노드(node)나 꼭지점(vertex)로 연결 되어 있는 개체(entity)의 집합을 부르는 용어다. 노드들은 변(edge)을 통해 서로 연결되어 있다. \n",
    "\n",
    "![](./images/graph.png)\n",
    "\n",
    "데이터 흐름 그래프에서(DataFlow Grapy)의 변(edge) 어떤 노드에서 다른 노드로 흘러가는(flow) 데이터의 방향을 정한다.\n",
    "\n",
    "텐서플로에서 그래프의 각 **노드는 하나의 연산을 나타내며, 입력값을 받아 다른 노드로 전달할 결과값을 출력**한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2 연산 그래프의 장점\n",
    "\n",
    "텐서플로는 그래프의 연결 상태를 기반으로 연산을 최적화한다. 각 그래프에는 노드 간에 의존관계(dependency)가 존재한다.. 예를 들어, 아래의 그림 'A'에서 노드 `e`는 노드 `c`에 **직접의존**(direct dependeny)하고 있고, 노드 `a`에는 **간접의존**(indirect dependency) 한다.\n",
    "\n",
    "![](./images/graph02.png)\n",
    "\n",
    "위의 그림에서 노드`e`를 계산하기 위해서는 노드 `c, b, a`만 계산 해주면 된다. 따라서, **의존관계를 이용해 연산량이 최소화**할 수 있다. 이처럼 그래프를 통해 각 노드의 모든 의존관계를 파악할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 그래프, 세션, 페치"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 그래프 만들기\n",
    "\n",
    "`import tensorflow as tf`를 통해 텐서플로를 import 하면 그 시점에 비어 있는 기본 그래프가 만들어지며, 우리가 만드는 모든 노드들은 이 기본 그래프에 자동으로 연결된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음과 같이 간단한 6개의 노드를 만들어 보자. 먼저 `a, b, c` 노드에 `5, 2, 3`을 대입한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.constant(5)\n",
    "b = tf.constant(2)\n",
    "c = tf.constant(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음 `d, e, f` 노드에는 `a, b, c`노드를 이용하여 간단한 연산을 수행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = tf.multiply(a, b)  # a * b\n",
    "e = tf.add(c, b)  # c + b\n",
    "f = tf.subtract(d, e)  # d - e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위에서 정의한 노드 및 연산을 그래프로 그려보면 아래와 같다.\n",
    "\n",
    "<img src=\"./images/graph03.png\" width=\"60%\" height=\"60%\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텐서플로에서는 위의 코드처럼 곱셈, 덧셈, 뺄셈을 텐서플로의 `tf.<operator>`를 사용하여 나타낼 수 있을 뿐만아니라 축약 연산자 즉, `*, +, -` 등을 사용할 수 있다.\n",
    "\n",
    "| TensorFlow 연산      | 축약 연산자 | 설명                                                       |\n",
    "| -------------------- | ----------- | ---------------------------------------------------------- |\n",
    "| `tf.add()`           | `a + b`     | a와 b를 더함                                               |\n",
    "| `tf.multiply()`      | `a * b`     | a와 b를 곱함                                               |\n",
    "| `tf.subtract()`      | `a - b`     | a에서 b를 뺌                                               |\n",
    "| `tf.divide()`        | `a / b`     | a를 b로 나눔                                               |\n",
    "| `tf.pow()`           | `a ** b`    | $a^b$ 를 계산                                              |\n",
    "| `tf.mod()`           | `a % b`     | a를 b로 나눈 나머지를 구함                                 |\n",
    "| `tf.logical_and()`   | `a & b`     | a와 b의 논리곱을 구함. `dtype`은 반드시 `tf.bool`이어야 함 |\n",
    "| `tf.greater()`       | `a > b`     | $a > b$ 의 True/False 값을 반환                            |\n",
    "| `tf.greater_equal()` | `a >= b`    | $a \\ge b$ 의 True/False 값을 반환                          |\n",
    "| `tf.less_equal()`    | `a <= b`    | $ a \\le b$ 의 True/False 값을 반환                         |\n",
    "| `tf.less()`          | `a < b`     | $a < b$ 의 True/False 값을 반환                            |\n",
    "| `tf.negative()`      | `-a`        | a의 반대 부호 값을 반환                                    |\n",
    "| `tf.logical_not()`   | `~a`        | a의 반대의 참거짓을 반환. `tf.bool` 텐서만 적용 가능       |\n",
    "| `tf.abs()`           | `abs(a)`    | a의 각 원소의 절대값을 반환                              |\n",
    "| `tf.logical_or()`    | `a I b`     | a와 b의 논리합을 구함. `dtype`은 반드시 `tf.bool`이어야 함 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 세션을 만들고 실행하기\n",
    "\n",
    "3.2.1에서 정의한 노드 및 연산 그래프를 실행하려면 아래의 코드 처럼 **세션(Session)**을 만들고 실행하면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outs = 5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 노드 및 연산 그래프 정의\n",
    "a = tf.constant(5)\n",
    "b = tf.constant(2)\n",
    "c = tf.constant(3)\n",
    "\n",
    "d = tf.multiply(a, b)  # a * b\n",
    "e = tf.add(c, b)  # c + b\n",
    "f = tf.subtract(d, e)  # d - e\n",
    "\n",
    "# 세션을 만들고 연산그래프 실행\n",
    "sess = tf.Session()\n",
    "outs = sess.run(f)\n",
    "sess.close()\n",
    "print(\"outs = {}\".format(outs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "먼저, `tf.Session()`에서 그래프를 시작한다. `Session`객체는 파이썬 객체와 데이터, 객체의 메모리가 할당되어 있는 실행 환경 사이를 연결하며, 중간 결과를 저장하고 최종 결과를 작업 환경으로 보내준다. 위의 코드에서는 `Session` 객체를 `sess = tf.Session()` 에 정의했다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "연산 그래프를 실행하려면 `Session`객체의 `run()` 메소드를 사용해야한다. 위의 코드에서 `sess.run(f)`는 아래의 그림처럼 출력이 나와야 하는 `f`노드에서 시작해서 역방향으로 의존관계에 따라 노드의 연산을 수행한다. \n",
    "\n",
    "<img src=\"./images/graph04.png\" width=\"60%\" height=\"60%\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "연산 수행이 완료되면 `sess.close()`를 통해 사용한 메모리를 해제하는 것이 좋다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3 그래프의 생성과 관리\n",
    "\n",
    "3.2.1에서 살펴 보았듯이, 텐서플로를 import 하면 바로 기본 그래프가 자동으로 만들어진다. 이 뿐만아니라 그래프를 추가로 생성하고 특정 연산의 관계를 직접 제어할 수도 있다. `tf.Graph()`는 텐서플로 객체로 표현되는 새로운 그래프를 만든다. 아래의 코드는 새로운 그래프를 만든 후 `g`에 할당한 코드이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default graph : <tensorflow.python.framework.ops.Graph object at 0x0000025EEE9578D0>\n",
      "new graph : <tensorflow.python.framework.ops.Graph object at 0x0000025EEE975898>\n",
      "a 노드가 g 그래프와 연결 되어 있나? : False\n",
      "a 노드가 기본 그래프와 연결 되어 있나? : True\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "\n",
    "# 새 그래프(Graph) 생성\n",
    "g = tf.Graph()\n",
    "\n",
    "print('default graph :', tf.get_default_graph())  # default graph \n",
    "print('new graph :', g)  # new graph\n",
    "\n",
    "a = tf.constant(5)  # a 노드 생성\n",
    "\n",
    "print('a 노드가 g 그래프와 연결 되어 있나? :', a.graph is g)\n",
    "print('a 노드가 기본 그래프와 연결 되어 있나? :', a.graph is tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 코드에서 보면 기본 그래프(`tf.get_default_graph()`)와 `g` 그래프(`g = tf.Graph()`)는 다른 텐서플로 객체임을 알 수 있다. \n",
    "\n",
    "또한, 노드 `a`에서 `a.graph`를 통해 `a`가 어떤 그래프에 연결되어 있는지 알 수 있다. 위의 코드에서는 새로운 그래프 `g`를 생성하였지만, 이 `g`그래프를 기본 그래프로 **지정** 해주지 않아 노드 `a`는 텐서플로를 import 하면서 생성된 기본 그래프에 연결 되어 있음을 알 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `with` 구문을 사용한 그래프 연결하기\n",
    "\n",
    "Python의 `with` 구문을 이용하면 원하는 그래프와 연결할 수 있다. `with`구문은 코드 실행이 **시작** 할 때 **설정**이 필요하고 코드가 종료 되는 시점에 **해제**가 필요한 경우에 사용하면 편리한 문법이다. \n",
    "\n",
    "이러한 `with` 구문에서 `as_default()` 메소드를 사용하면 해당 그래프를 기본 그래프로 지정해준다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g2가 기본 그래프인가? :  False\n",
      "g2가 기본 그래프인가? :  True\n",
      "g2가 기본 그래프인가? :  False\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "g1 = tf.get_default_graph()\n",
    "g2 = tf.Graph()\n",
    "\n",
    "# g2 그래프가 기본 그래프인지 확인\n",
    "print('g2가 기본 그래프인가? : ', g2 is tf.get_default_graph())\n",
    "\n",
    "# with 구문을 이용한 \n",
    "# g2를 기본 그래프로 지정하기\n",
    "with g2.as_default():\n",
    "    print('g2가 기본 그래프인가? : ', g2 is tf.get_default_graph())\n",
    "\n",
    "# with 구문이 끝났으므로 \n",
    "# g2를 기본 그래프에서 해제\n",
    "print('g2가 기본 그래프인가? : ', g2 is tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.4 페치(fetch)\n",
    "\n",
    "3.2.2 예제에서 `sess.run(f)` 를 통해 `f`노드를 실행했다. 이처럼 `sess.run()`의 **인자**(parameter)인 `f`를 **페치(fetches)** 라고 하며, **연산하고자 하는 그래프의 요소에 해당**한다. 페치는 하나의 노드가 되거나 노드들로 이루어진 리스트(list)이다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outs = [5, 2, 3, 10, 5, 5]\n",
      "<class 'numpy.int32'>\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    fetches = [a, b, c, d, e, f]\n",
    "    outs = sess.run(fetches)\n",
    "    \n",
    "print(\"outs = {}\".format(outs))\n",
    "print(type(outs[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 텐서의 흐름\n",
    "\n",
    "이제 텐서플로에서 노드(node)와 엣지(edge)가 실제로 표현되는 방법 및 컨트롤하는 방법을 알아보도록 하자. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1 노드는 연산, 엣지는 텐서 객체\n",
    "\n",
    "앞의 예제에서 보았듯이, `tf.add(), tf.multiply()` 등으로 그래프에서 노드(node)를 만들 때, 실제로는 **연산 인스턴스가 생성**된다. 생성된 연산(인스턴스)들은 그래프가 실행되기 전까지는 연산한 값을 반환하지 않고, 계산된 결과를 다른 노드로 전달할 수 있는 핸들(handle), 즉 **흐름(flow)**으로 참조된다. 이러한 핸들은 그래프에서 엣지(edge)라고 할 수 있으며, 텐서 객체(Tensor object)라고 한다.\n",
    "\n",
    "텐서플로는 모든 구성 요소가 담긴 그래프의 골격을 먼저 만들도록 설계되었다. 이 시점에는 실제 텐서(데이터)는 흐르지 않으며 연산 또한 수행되지 않는다. 세션(Session)이 실행되면 그래프에 텐서가 입력되고 연산이 수행된다.\n",
    "\n",
    "<img src=\"./images/node_edge.png\" width=\"75%\" height=\"75%\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래의 예제코드는 세션이 실행되기 전과 실행된 후의 텐세객체를 출력한 예제이다. 아래의 출력결과에서 볼 수 있듯이, 텐서플로의 텐서 객체는 `name, shape, dtype` 속성이 있어 해당 객체의 특징을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session이 실행되기 전 : Tensor(\"Const_13:0\", shape=(2, 2), dtype=int32)\n",
      "Session이 실행된 후 :\n",
      " [[1 2]\n",
      " [3 4]]\n"
     ]
    }
   ],
   "source": [
    "tensor_a = tf.constant([[1, 2], [3, 4]])\n",
    "\n",
    "print('Session이 실행되기 전 :', tensor_a)\n",
    "\n",
    "sess = tf.Session()\n",
    "out = sess.run(tensor_a)\n",
    "print('Session이 실행된 후 :\\n', out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2 데이터 타입\n",
    "\n",
    "그래프를 통해 전달되는 데이터의 기본 단위는 숫자, 참거짓값(`True, False`), 스트링 요소들이다. \n",
    "\n",
    "<img src=\"./images/data_type.png\" width=\"75%\" height=\"75%\" />\n",
    "\n",
    "3.3.1의 예제에서 `tensor_a = tf.constant([[1, 2], [3, 4]])`는 데이터타입(`dtype`)을 정의하지 않았기 때문에 텐서플로가 자동으로 `int32`로 데이터 타입을 추측했다. 아래와 텐서 객체를 만들 때 데이터 타입을 정의해줄 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_14:0\", shape=(2, 2), dtype=float64)\n",
      "<dtype: 'float64'>\n"
     ]
    }
   ],
   "source": [
    "tensor_a = tf.constant([[1, 2], [3, 4]], dtype=tf.float64)\n",
    "print(tensor_a)\n",
    "print(tensor_a.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 형 변환 (Casting)\n",
    "\n",
    "텐서플로에서 일치하지 않는 두 데이터 타입을 가지고 연산을 실행하면 예외가 발생하므로 그래프에서 데이터 타입이 일치하는지 확인하는 것이 중요하다. 아래의 표와 같이 텐서플로는 다양한 데이터타입을 지원한다.\n",
    "\n",
    "| 데이터 타입 이름 | 파이썬 데이터 타입 | 설명                                                         |\n",
    "| :--------------- | :----------------- | :----------------------------------------------------------- |\n",
    "| DT_FLOAT         | `tf.float32`       | 32비트 부동소수점 숫자                                       |\n",
    "| DT_DOUBLE        | `tf.float64`       | 64비트 부동소수점 숫자                                       |\n",
    "| DT_INT8          | `tf.int8`          | 8비트 정수                                                   |\n",
    "| DT_INT16         | `tf.int16`         | 16비트 정수                                                  |\n",
    "| DT_INT32         | `tf.int32`         | 32비트 정수                                                  |\n",
    "| DT_INT64         | `tf.int64`         | 64비트 정수                                                  |\n",
    "| DT_UINT8         | `tf.uint8`         | 8비트 부호 없는 정수                                         |\n",
    "| DT_UINT16        | `tf.uint16`        | 16비트 부호 없는 정수                                        |\n",
    "| DT_STRING        | `tf.string`        | 가변 길이 바이트 배열이며 텐서의 각 요소는 바이트의 배열     |\n",
    "| DT_BOOL          | `tf.bool`          | 참거짓값                                                     |\n",
    "| DT_COMPLEX64     | `tf.complex64`     | 2개의 32비트 부동소수점 숫자로 구성된 복소수로 각각 실수부와 허수부 |\n",
    "| DT_COMPLEX128    | `tf.complex128`    | 2개의 64비트 부동소수점 숫자로 구성된 복소수로 각각 실수부와 허수부 |\n",
    "| DT_QINT8         | `tf.qint8`         | 양자화 연산(quantized operation)에 사용되는 8비트 정수       |\n",
    "| DT_QINT32        | `tf.qint32`        | 양자화 연산에 사용되는 32비트 정수                           |\n",
    "| DT_QUINT8        | `tf.quint8`        | 양자화 연산에 사용되는 8비트 부호 없는 정수                  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.3 텐서 배열과 형태\n",
    "\n",
    "텐서플로에서 텐서(Tensor)는 다음과 같이 두 가지 의미로 볼 수 있다.\n",
    "\n",
    "- 그래프에서 연산의 결과, 파이썬 API에서 사용하는 객체의 이름\n",
    "- $n$차원 배열을 가리키는 수학 용어. \n",
    "    - $1 \\times 1$ 텐서는 스칼라, $1 \\times n$ 텐서는 벡터, $n \\times n$ 텐서는 행렬, $n \\times n \\times n$ 텐서는 3차원 배열\n",
    "    - 텐서플로에서는 다차원 배열, 벡터, 행렬, 스칼라 등을 그래프에서 전달되는 모든 데이터를 **텐서**로 간주한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파이썬의 자료형인 리스트(list)나 NumPy의 배열을 사용하여 텐서를 초기화할 수 있다. 아래의 예제는 이 두가지를 사용하여 텐서를 초기화 하는 예제다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python List input : (2, 3)\n",
      "3d NumPy array input : (2, 2, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "c = tf.constant([[1, 2, 3], \n",
    "                 [4, 5, 6]])\n",
    "print('Python List input :', c.get_shape())\n",
    "\n",
    "c = tf.constant(np.array([\n",
    "                  [[1, 2, 3], \n",
    "                   [4, 5, 6]],\n",
    "                    \n",
    "                  [[1, 1, 1], \n",
    "                   [2, 2, 2]]\n",
    "                ]))\n",
    "\n",
    "print(\"3d NumPy array input :\", c.get_shape())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 예제에서 `get_shape()` 메소드는 텐서의 형태(shape)를 튜플로 반환한다. 튜플 원소의 개수는 텐서의 차원 수에 해댕한다. 예를 들어 `(2, 3)` 튜플은 2개의 원소로 이루어져 있는 행렬이고, 각 원소를 통해 `2 x 3`인 것을 할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 난수 생성\n",
    "\n",
    "난수 생성은 텐서플로 변수의 초기값을 정의할 때 자주 사용되므로 중요하다. 다음 코드는 주로 사용되는 정규분포(normal distribution)와 균등분포(uniform distribution)을 구현한 코드이다. 형태(shape), 평균($\\mu$), 표준편차($\\sigma$)를 tf.random_normal()의 인자에 넣어주면 **정규분포**를 따르는 난수들을 생성할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.pylabtools import figsize\n",
    "\n",
    "matplotlib.rc('font', family='NanumGothic')  # Linumx\n",
    "# matplotlib.rc('font', family='AppleGothic')  # Mac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# === Normal and Truncated normal distribution === \n",
    "mean, std = 0, 1\n",
    "x_normal = tf.random_normal((1, 50000), mean, std).eval()  # shape = (1, 50000)\n",
    "x_truncated = tf.truncated_normal((1, 50000), mean, std).eval()\n",
    "\n",
    "# === Uniform distribution ===\n",
    "minval, maxval = -2, 2\n",
    "x_uniform = tf.random_uniform((1, 50000), minval, maxval).eval()\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x288 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# matplotlib 설정 부분\n",
    "def simpleaxis(ax):\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.get_xaxis().tick_bottom()\n",
    "    ax.get_yaxis().tick_left()\n",
    "    ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "    \n",
    "def get_axis_limits(ax, scale=.8):\n",
    "    return ax.get_xlim()[1]*scale, ax.get_ylim()[1]*scale\n",
    "\n",
    "f,axarr = plt.subplots(1,3,figsize=[15,4],sharey=True)\n",
    "titles = ['정규분포','절단정규분포','균등분포']\n",
    "\n",
    "for i,x in enumerate([x_normal,x_truncated,x_uniform]):\n",
    "    ax = axarr[i]\n",
    "    ax.hist(x[0], bins=100, alpha=0.4)\n",
    "    ax.set_title(titles[i], fontsize=20)\n",
    "    ax.set_xlabel('Values', fontsize=20)\n",
    "    ax.set_xlim([-5, 5])\n",
    "    ax.set_ylim([0, 1800])\n",
    "    \n",
    "    simpleaxis(ax)\n",
    "    \n",
    "axarr[0].set_ylabel('Frequency', fontsize=20)\n",
    "plt.suptitle('난수 생성', fontsize=30, y=1.15)\n",
    "\n",
    "for ax,letter in zip(axarr,['A','B','C']):\n",
    "    simpleaxis(ax)\n",
    "    ax.annotate(letter, xy=get_axis_limits(ax),fontsize=35)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf.InteractiveSession()`와 `.eval()`을 사용하면 텐서 객체의 데이터를 쉽게 확인할 수 있다. \n",
    "\n",
    "> `tf.InteractiveSession()`은 연산 실행에 필요한 세션을 저장할 변수를 따로 지정하지 않아도 된다. 주피터 노트북과 같은 대화형 파이썬 환경에서 사용할 때 편리하다.\n",
    "\n",
    "아래의 예제는 `tf.InteractiveSession()`, `.eval()`을 사용한 예제이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The content of 'c': \n",
      " [0. 1. 2. 3. 4.]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sesss = tf.InteractiveSession()\n",
    "\n",
    "# 0.0 ~ 4.0 을 같은 간격으로 5개 값 생성\n",
    "c = tf.linspace(0.0, 4.0, 5)  \n",
    "\n",
    "print(\"The content of 'c': \\n {}\\n\".format(c.eval()))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음은 텐서플로에서 사용되는 초기화 함수를 표로 정리한 것이다.\n",
    "\n",
    "| 텐서플로 연산                              | 설명                                                         |\n",
    "| ------------------------------------------ | ------------------------------------------------------------ |\n",
    "| `tf.constant(value)`                       | 인수 `value`에 지정한 값 또는 값들로 채워진 텐서를 생성      |\n",
    "| `tf.fill(shape, value)`                    | `shape`에 지정한 형태의 텐서를 만들고, `value`에 지정한 값으로 초기화 |\n",
    "| `tf.zeros(shape)`                          | `shape`에 지정한 형태의 텐서를 만들고, 모든 원소의 값을 `0`으로 초기화 |\n",
    "| `tf.zeros_like(tensor)`                    | `tensor`와 동일한 타입과 형태의 텐서를 만들고, 모든 원소의 값을 `0`으로 초기화 |\n",
    "| `tf.ones(shape)`                           | `shape`에 지정한 형태의 텐서를 만들고, 모든 원소의 값을 `1`로 초기화 |\n",
    "| `tf.ones_like(tensor)`                     | `tensor`와 동일한 타입과 형태의 텐서를 만들고, 모든 원소의 값을 `1`로 초기화 |\n",
    "| `tf.random_normal(shape, mean, stddev)`    | 정규분포를 따르는 난수를 생성                                |\n",
    "| `tf.truncated_normal(shape, mean, stddev)` | 절단정규분포(평균을 기준으로 표준편차보다 크거나 작은 데이터를 제외)를 따르는 난수를 생성 |\n",
    "| `tf.random_uniform(shape, minval, maxval)` | `[minval, maxval)` 구간의 균등분포의 값을 생성               |\n",
    "| `tf.random_shuffle(tensor)`                | 첫 번째 차원에 따라 텐서를 무작위로 뒤섞음                   |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 행렬곱\n",
    "\n",
    "텐서플로에서 행렬곱은 `tf.matmul()` 함수를 이용하여 연산을 수행한다. 예를 들어, 두 텐서 객체 A와 B의 행렬곱은 `tf.matmul(A, B)`로 계산할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matmul restlt:\n",
      " [[ 8  5]\n",
      " [20 13]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\cjh\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1711: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "A = tf.constant([[1, 2], \n",
    "                 [3, 4]])\n",
    "\n",
    "B = tf.constant([[4, 3], \n",
    "                 [2, 1]])\n",
    "\n",
    "AB = tf.matmul(A, B)\n",
    "\n",
    "tf.InteractiveSession()\n",
    "print('matmul restlt:\\n {}'.format(AB.eval()))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.4 이름\n",
    "\n",
    "텐서플로에서는 각 텐서 객체마다 고유의 이름을 가진다. 이러한 이름은 텐서플로 내부에서 사용하는 string형태의 이름이다. 아래의 예제는 텐서 객체의 인자에 `name`을 사용해 이름을 지정한 뒤 `.name`속성을 통해 이름을 확인하는 코드다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:0\n",
      "c_1:0\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "    c1 = tf.constant(4, dtype=tf.float64, name='c')\n",
    "    c2 = tf.constant(4, dtype=tf.int32, name='c')\n",
    "    \n",
    "print(c1.name)\n",
    "print(c2.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 코드에서 `c1`과 `c2` 둘 다에 `name='c'`라고 하여 같은 이름 즉, 중복된 이름을 가진다. 텐서플로에서는 **하나의 그래프 내의 객체는 동일한 이름을 가질 수 없다**. 위의 코드와 같은 경우에는 `c1`과 `c2` 두 객체를 구분하기 위해 `_숫자`가 자동으로 붙는다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 이름 스코프\n",
    "\n",
    "복잡한 그래프를 처리해야 하는 경우 이를 쉽게 추적하고 관리하기 위해서 노드를 이름별로 그룹화하여 묶는 것이 편리하다. `with`구문과 `tf.name_scope('prefix')`를 사용하면 이름 스코프를 사용할 수 있다.\n",
    "\n",
    "아래의 예제는 `c2, c3`를 `prefix_name`이라는 스코프로 그룹화한 것이다. 출력결과를 보면 텐서 객체의 이름 앞에 접두사 형태로 `prefix_name`이 붙은 것을 알 수 있다. \n",
    "\n",
    "접두사는 그래프를 의미에 따라 서브그래프로 나누고자 할 때 유용하며, 그래프의 구조를 시각화할 때 사용할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c1.name >> c:0\n",
      "c2.name >> prefix_name/c:0\n",
      "c3.name >> prefix_name/c_1:0\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "    c1 = tf.constant(4, dtype=tf.float64, name='c')\n",
    "    with tf.name_scope(\"prefix_name\"):\n",
    "        c2 = tf.constant(4, dtype=tf.int32, name='c')\n",
    "        c3 = tf.constant(4, dtype=tf.float64, name='c')\n",
    "\n",
    "print('c1.name >>', c1.name)\n",
    "print('c2.name >>', c2.name)\n",
    "print('c3.name >>', c3.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 변수, 플레이스홀더, 간단한 최적화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.1 변수\n",
    "\n",
    "딥러닝 학습에서 최적화 과정은 주어진 모델의 매개변수(parameters) 즉, 가중치(및 편향)를 조정하는 것이라 할 수 있다. 텐서플로에서는 이러한 최적화 과정에서 **변수(Variable)** 라는 객체를 사용한다. 변수는 세션이 실행될 때 마다 그래프에서 고정된 상태를 유지할 수 있다. 그렇기 때문에 변수는 최적화를 위한 반복 과정에서 현재의 변수가 다음 반복 과정에 영향을 줄 수 있다.\n",
    "\n",
    "변수의 사용은 두 단계로 나뉜다.\n",
    "\n",
    "1. `tf.Variable()`함수를 사용해 변수를 만들고 어떤 값으로 초기화할지를 정의한다.\n",
    "2. `tf.global_variables_initializer()` 메소드를 사용하여 세션에 초기화 연산을 수행해야 하며, 변수에 메모리를 할당하고 초기값을 설정하는 역할을 한다.\n",
    "\n",
    "다른 텐서 객체와 마찬가지로 변수 또한 그래프가 실행될 때 계산된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre run: \n",
      "<tf.Variable 'var:0' shape=(1, 5) dtype=float32_ref>\n",
      "\n",
      "post run: \n",
      "[[ 0.2887228   0.50184816  1.1468904  -0.30481052 -1.4262516 ]]\n"
     ]
    }
   ],
   "source": [
    "init_val = tf.random_normal((1, 5), 0, 1)\n",
    "var = tf.Variable(init_val, name='var')\n",
    "print(\"pre run: \\n{}\".format(var))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    post_var = sess.run(var)\n",
    "    \n",
    "print('\\npost run: \\n{}'.format(post_var))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 코드를 다시 실행할 때 마다 변수 이름인 `var`에 `_숫자`가 붙는 것을 확인할 수 있다. 따라서, 세션을 실행할 때마다 값이 덮어씌어 지는것이 아니라 새로운 변수가 만들어지는 것을 알 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.2 플레이스홀더\n",
    "\n",
    "딥러닝에서 데이터에 대한 학습이 이루어질 때 학습할 데이터들을 입력해줘야 한다. 예를 들어, [2장](http://excelsior-cjh.tistory.com/149)에서 잠깐 살펴보았던, MNIST 데이터를 학습한다고 할때 입력값으로 MNIST 이미지 데이터를 입력값으로 넣어 줘야 했다. 텐서플로에서는 입력값을 넣어주기 위해 **플레이스홀더(placeholder)**라는 것이 있다. 플레이스홀더는 데이터를 입력받는 비어있는 변수라고 생각할 수 있다. 먼저 그래프를 구성하고, 그 그래프가 실행되는 시점에 입력 데이터를 넣어주는 데 사용한다.\n",
    "\n",
    "플레이스홀더는 `shape` 인수를 유동적으로 지정할 수 있다. 예를 들어, `None`으로 지정되면 이 플레이스홀더는 모든 크기의 데이터를 받을 수 있다. 주로 배치단위(batch size)의 샘플 데이터 개수에 해당 되는 부분(데이터의 행)은 `None`을 사용하고, 데이터 Feature의 길이(데이터의 열)는 고정된 값을 사용한다. \n",
    "\n",
    "```python\n",
    "ph = tf.placeholder(tf.float32, shape=(None, 10))\n",
    "```\n",
    "\n",
    "플레이스홀더를 정의하면 반드시 그래프 실행 단계에서 입력값을 넣어줘야 하며, 그렇지 않을 경우 에러가 나타난다. 입력 데이터는 딕셔너리(dictionary)형태로 `session.run()`메소드를 통해 전달된다. 딕셔너리의 키(key)는 플레이스홀더 변수 이름에 해당하며 값(value)은 list 또는 NumPy 배열이다.\n",
    "\n",
    "```python\n",
    "sess.run(s, feed_dict={ph: data})\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음 예제를 통해 플레이스홀더에 입력데이터를 넣어주는 것을 알아보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outs = 3.2797560691833496\n"
     ]
    }
   ],
   "source": [
    "x_data = np.random.randn(5, 10)\n",
    "w_data = np.random.randn(10, 1)\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "    x = tf.placeholder(tf.float32, shape=(5, 10))\n",
    "    w = tf.placeholder(tf.float32, shape=(10, 1))\n",
    "    b = tf.fill((5, 1), -1.)\n",
    "    xw = tf.matmul(x, w)\n",
    "    \n",
    "    xwb = xw + b\n",
    "    s = tf.reduce_max(xwb)\n",
    "    with tf.Session() as sess:\n",
    "        outs = sess.run(s, feed_dict={x: x_data, w: w_data})\n",
    "    \n",
    "    print(\"outs = {}\".format(outs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.3 최적화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 손실 함수 정의하기\n",
    "\n",
    "모델을 최적화하기 위해서는 모델의 성능을 평가할 수 있는 척도가 필요하며, 모델이 예측한 값과 관측값 사이의 불일치 정도를 확인하려면 **'거리'**를 반영하는 척도가 필요하다. 이러한 거리를 **손실(loss)**함수라고 하며, 이 **함수의 값을 최소화하는 파라미터(가중치, 편향)을 찾아내는 것**이 딥러닝 모델을 최적화하는 것이다.\n",
    "\n",
    "보통 손실함수는 실제와 이론을 모두 구려해 가장 적절한 것을 선택하므로 정확한 손실함수는 존재하지 않는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 평균제곱오차와 교차 엔트로피"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 평균제곱오차(MSE)\n",
    "\n",
    "가장 흔하게 사용되는 손실함수는 평균제곱오차(MSE, Mean Square Error)이다. 모든 데이터 샘플에서 실제 관측값과 모델 예측값 사이의 차를 제곱한 값의 평균이다.\n",
    "\n",
    "$$\n",
    "L \\left(y, \\hat{y}\\right) = \\frac{1}{n} \\sum_{i=1}^{n}{\\left( y_i - \\hat{y}_i \\right)^{2}}\n",
    "$$\n",
    "\n",
    "즉, 실제 관측된 값과 모델의 적합값(fitted value, 예측값) 사이의 차이(잔차, residual)의 제곱값의 평균을 최소화하는 것이다.\n",
    "\n",
    "텐서플로에서는 다음과 같이 MSE를 계산할 수 있다. \n",
    "\n",
    "```python\n",
    "loss = tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "# OR\n",
    "loss = tf.losses.mean_squared_error(y_true, y_pred)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 교차 엔트로피 (Cross Entropy)\n",
    "\n",
    "교차 엔트로피는 주로 범주형 데이터에 사용되는 손실함수이며, 다음과 같다.\n",
    "\n",
    "$$\n",
    "CEE = - \\frac{1}{n} \\sum_{i}{\\left[ y_i \\log \\hat{y}_i + (1-y_i) \\log \\left( 1-\\hat{y}_i \\right) \\right]}\n",
    "$$\n",
    "\n",
    "이를 텐서플로에서 다음과 같이 작성할 수 있다.\n",
    "\n",
    "```python\n",
    "loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=y_true, logits_y_pred)\n",
    "loss = tf.reduce_mean(loss)\n",
    "```\n",
    "\n",
    "교차 엔트로피는 두 분포 사이의 유사성을 측정하는 척도이다. 딥러닝에서의 분류 모델은 각 클래스의 확률값을 계산하므로 실제 클래스(`y_true`)와 모델이 예측한 클래스(`y_pred`)를 비교할 수 있으며, 두 분포가 가까울수록 교차 엔트로피값은 더 작아진다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 경사 하강법(Gradient Descent) 최적화 함수\n",
    "\n",
    "딥러닝에서 손실함수를 최소화하는 다양한 최적화 알고리즘들이 있다. 가장 흔히 사용되는 알고리즘으로는 가중치의 집합에 대한 손실의 경사(기울기)를 이용한 **경사 하강법(gradient descent)**이 있다. \n",
    "\n",
    "$$\n",
    "\\mathrm{W} \\leftarrow \\mathrm{W} - \\eta \\frac{\\partial L}{\\partial \\mathrm{W}}\n",
    "$$\n",
    "\n",
    "![](./images/gd.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "경사 하강법의 가장 보편적인 방법은 **확률적 경사 하강법(SGD, Stochastic Gradient Descent)**으로 학습해야할 전체 데이터를 계산하는 것이 아닌 일부 데이터를 미니배치(mini-batch, 50 ~ 500개 사이)단위로 추출하여 경사 하강법을 계산한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 텐서플로의 경사 하강법\n",
    "\n",
    "텐서플로에서는 경사 하강법을 간단하게 사용할 수 있다. 아래의 코드만 작성해주면 경사 하강법을 이용해 자동으로 경사값(기울기)을 구해준다. \n",
    "\n",
    "```python\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "train = optimizer.minimize(loss)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.4 예제를 통한 최적화 과정\n",
    "\n",
    "앞에서 배운 내용을 토대로 선형회귀(Linear Regression)과 로지스틱 회귀(Logistic Regression) 두 모델의 매개변수(가중치, 편향)를 최적화 해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 예제 1: Linear Regression\n",
    "\n",
    "예제 1은 각 샘플에 가우시안 노이즈 $\\varepsilon_i$를 추가한 입력 벡터 $x$일때 가중치 $w$와 편향값 $b$를 찾아내는 문제이다.\n",
    "\n",
    "$$\n",
    "y_i = w^{T} x_i + b + \\varepsilon_i\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Create data and simulate results ===\n",
    "\n",
    "# shape = (2000, 3)인 정규분포(mu=0, sigma=1)\n",
    "x_data = np.random.randn(2000, 3)\n",
    "w_real = [0.3, 0.5, 0.1]\n",
    "b_real = -0.2\n",
    "\n",
    "# 가우시안 노이즈\n",
    "noise = np.random.randn(1, 2000) * 0.1\n",
    "\n",
    "y_data = np.matmul(w_real, x_data.T) + b_real + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [array([[0.28029504, 0.4805126 , 0.10058896]], dtype=float32), -0.21319611]\n",
      "5 [array([[0.29576042, 0.4981753 , 0.1022327 ]], dtype=float32), -0.20189795]\n",
      "10 [array([[0.29576045, 0.4981753 , 0.1022327 ]], dtype=float32), -0.20189795]\n"
     ]
    }
   ],
   "source": [
    "NUM_STEPS = 10\n",
    "\n",
    "g = tf.Graph()\n",
    "wb_ = []\n",
    "\n",
    "with g.as_default():\n",
    "    x = tf.placeholder(tf.float32, shape=[None, 3])\n",
    "    y_true = tf.placeholder(tf.float32, shape=None)\n",
    "    \n",
    "    with tf.name_scope('inference') as scope:\n",
    "        w = tf.Variable([[0, 0, 0]], dtype=tf.float32, name='weights')\n",
    "        b = tf.Variable(0, dtype=tf.float32, name='bias')\n",
    "        y_pred = tf.matmul(w, tf.transpose(x)) + b\n",
    "        \n",
    "    with tf.name_scope('loss') as scope:\n",
    "        # loss = tf.reduce_mean(tf.square(y_true - y_pred))  # MSE\n",
    "        loss = tf.losses.mean_squared_error(y_true, y_pred)\n",
    "        \n",
    "    with tf.name_scope('train') as scope:\n",
    "        learning_rate = 0.5\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "        train = optimizer.minimize(loss)\n",
    "        \n",
    "    # Before starting, initialize the variables.\n",
    "    init = tf.global_variables_initializer()\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        for step in range(NUM_STEPS):\n",
    "            sess.run(train, feed_dict={x: x_data, y_true: y_data})\n",
    "            if step % 5 == 0:\n",
    "                print(step, sess.run([w, b]))\n",
    "                wb_.append(sess.run([w, b]))\n",
    "        print(10, sess.run([w, b]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 결과를 보면 10회 학습으로 추정 가중치 $\\hat{w} = \\left[0.29576045, 0.4981753 , 0.1022327 \\right]$ 이고, 추정 편향값 $\\hat{b} = -0.20189795$로 나타났다. 실제 매개변수 값인 $w = \\left[0.3, 0.5 , 0.1 \\right], b = -0.2$와 거의 비슷한 것을 알 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 예제 2: Logistic Regression\n",
    "\n",
    "이번에는 로지스틱 회귀를 알아보자. 로지스틱 회귀에서는 $w^{T} x + b$인 선형 성분은 로지스틱 함수인 비선형 함수의 입력이 되며, 이 함수의 결과값은 $[0, 1]$ 사이이다.\n",
    "\n",
    "$$\n",
    "\\text{Pr} \\left( y_i=1 | x_i \\right) = \\frac{1}{1+ \\text{exp}^{wx_i - b}}\n",
    "$$\n",
    "\n",
    "예제 2번에서 사용하는 로지스틱 함수는 **시그모이드 함수(sigmoid function)**라고도 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 20000\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# === Create data and simulate results ===\n",
    "x_data = np.random.randn(N, 3)\n",
    "w_real = [0.3, 0.5, 0.1]\n",
    "b_real = -0.2\n",
    "wxb = np.matmul(w_real, x_data.T) + b_real\n",
    "\n",
    "y_data_pre_noise = sigmoid(wxb)  # 이진화 전\n",
    "y_data = np.random.binomial(1, y_data_pre_noise)  # 이진화 후"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [array([[0.03201461, 0.05613991, 0.01390209]], dtype=float32), -0.02239997]\n",
      "10 [array([[0.2018806 , 0.34991866, 0.08566012]], dtype=float32), -0.13928187]\n",
      "20 [array([[0.25465283, 0.43867975, 0.10675137]], dtype=float32), -0.17420112]\n",
      "30 [array([[0.2726871 , 0.46833742, 0.11364853]], dtype=float32), -0.1857122]\n",
      "40 [array([[0.27905232, 0.47861528, 0.11599838]], dtype=float32), -0.18965253]\n",
      "50 [array([[0.28132075, 0.48222345, 0.11681207]], dtype=float32), -0.19102146]\n",
      "60 [array([[0.282131  , 0.48349622, 0.11709588]], dtype=float32), -0.19150014]\n",
      "70 [array([[0.2824203 , 0.483946  , 0.11719528]], dtype=float32), -0.19166814]\n",
      "80 [array([[0.28252348, 0.48410508, 0.11723018]], dtype=float32), -0.19172719]\n",
      "90 [array([[0.28256023, 0.48416138, 0.11724245]], dtype=float32), -0.19174801]\n",
      "100 [array([[0.28257257, 0.48418012, 0.11724652]], dtype=float32), -0.19175489]\n"
     ]
    }
   ],
   "source": [
    "NUM_STEPS = 100\n",
    "\n",
    "g = tf.Graph()\n",
    "wb_ = []\n",
    "with g.as_default():\n",
    "    x = tf.placeholder(tf.float32, shape=[None, 3])\n",
    "    y_true = tf.placeholder(tf.float32, shape=None)\n",
    "    \n",
    "    with tf.name_scope('inference') as scope:\n",
    "        w = tf.Variable([[0, 0, 0]], dtype=tf.float32, name='weights')\n",
    "        b = tf.Variable(0, dtype=tf.float32, name='bias')\n",
    "        y_pred = tf.matmul(w, tf.transpose(x)) + b\n",
    "        \n",
    "    with tf.name_scope('loss') as scope:\n",
    "        loss =tf.nn.sigmoid_cross_entropy_with_logits(labels=y_true, logits=y_pred)\n",
    "        loss = tf.reduce_mean(loss)\n",
    "        \n",
    "    with tf.name_scope('train') as scope:\n",
    "        learning_rate = 0.5\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "        train = optimizer.minimize(loss)\n",
    "        \n",
    "    # Before starting, initialize the variables\n",
    "    init = tf.global_variables_initializer()\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        for step in range(NUM_STEPS):\n",
    "            sess.run(train, feed_dict={x: x_data, y_true: y_data})\n",
    "            if step % 10 == 0:\n",
    "                print(step, sess.run([w, b]))\n",
    "                wb_.append(sess.run([w, b]))\n",
    "        \n",
    "        print(100, sess.run([w, b]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
